<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Posts on ze sheng</title><link>https://zes1092.github.io/posts/</link><description>Recent content in Posts on ze sheng</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><copyright/><lastBuildDate>Fri, 01 Apr 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://zes1092.github.io/posts/index.xml" rel="self" type="application/rss+xml"/><item><title>a tutorial</title><link>https://zes1092.github.io/posts/a-tutorial/</link><pubDate>Fri, 01 Apr 2022 00:00:00 +0000</pubDate><guid>https://zes1092.github.io/posts/a-tutorial/</guid><description>./pre-nut I don&amp;rsquo;t know how I&amp;rsquo;m supposed to view women like most men. I&amp;rsquo;ve heard some negative feedback on my ability to co-exist with whiny overdramatic females properly. What sticks out to me, is that they spend so much effort on looking good but their biggest issue with us is our creepy male gaze. She just wants to feel pretty and you&amp;rsquo;re telling her cheesy pickup lines from google. But it feels impossible to act normal around someone that&amp;rsquo;s literally carrying gold between their legs.</description><content type="html"><![CDATA[<h1 id="pre-nut">./pre-nut</h1>
<p>I don&rsquo;t know how I&rsquo;m supposed to view women like most men. I&rsquo;ve heard some negative feedback on my ability to co-exist with whiny overdramatic females properly. What sticks out to me, is that they spend so much effort on looking good but their biggest issue with us is our creepy male gaze. She just wants to feel pretty and you&rsquo;re telling her cheesy pickup lines from google. But it feels impossible to act normal around someone that&rsquo;s literally carrying gold between their legs. Even when she gets under your skin, what she got still feels worth it. You try to push away those feelings because when she realises your intention, she loses interest and kind of thinks you&rsquo;re pathetic. Your self-worth is dependent on her opinion and she starts resenting all the creepy jealous male anger that comes with it at some point. It&rsquo;s time to stop thinking like this. That&rsquo;s how the same woman who was pursued for her beauty ends up discarded and cut in half by some attractive guy. Maybe she can do more than spread her legs. Maybe if you look closer you&rsquo;ll see something you never noticed before. Maybe if you don&rsquo;t all the girls your age will have learned from their mistake and avoid some guy like you forever. But you also want to have the ability to sweep any girl off her feet, not in hopes that life is going to open the door for somebody better. But because you&rsquo;re insecure and women&rsquo;s admiration makes up for what you&rsquo;re lacking. It&rsquo;s selfish but you&rsquo;re tired of lifting women up on a pedestal only to doze off mid-conversation because you&rsquo;re talking to a girl who never had to develop a personality. Viewing women like romantic balls of joy is just as dumb as objectifying them because your heart will always get broken. Now, look at yourself. You&rsquo;re worried that if you keep viewing women as accessories for your life you will become a labeled incel. So it&rsquo;s time to go outside and meet real women platonic and celibate. I&rsquo;m going to do all the research I can on how to untoxify myself and figure out the right way to view women.</p>
<hr>
<h1 id="post-nut">./post-nut</h1>
<p>Every girl has a different answer I don&rsquo;t even think they know what they want to be viewed. They want you to be straightforward but not too straightforward. But not too straightforward creep. They want your attention but only at the perfect moment when they need it. They kind of expect you to know how to read their minds. I&rsquo;m starting to understand why a lot guys play it safe and stick to the hub. I&rsquo;m talking like this issue is universal. I attach so much importance to women&rsquo;s attention because I grew up not knowing how to socialise. When you can&rsquo;t get something, you start believing you won&rsquo;t be happy until you do, but your value as a man shouldn&rsquo;t depend on a woman. She simply wants somebody that doesn&rsquo;t need her instead. Instead of approaching women as a projection of your desires. It&rsquo;s better to see them as just other people. Usually, people are more interesting than they seem.</p>
<hr>
<h3 id="afterword">./afterword</h3>
<blockquote>
<p><code>I'm not an incel. I'm not this toxic person that I display here. Well I used to be. Very obviously put on in the beginning so that I can debunk an argument at the end. The misogyny that I'm trying to debunk is the whole part was trying to come off like a misogynist person. I'm taking a perspective of a socially angst man who doesn't know how to communicate. Knowing people who are like this, there's a bit of irony that I'm trying to convey a nuanced perspective to be controversial. If you want to say something truthful yet contentious and say what you really feel, you're going to risk having people canceling you. That is called growth.</code></p>
</blockquote>
<hr>
<p><em>~ inspired by she tyler the creator</em></p>
]]></content></item><item><title>fifteen million merits</title><link>https://zes1092.github.io/posts/fifteen-million-merits/</link><pubDate>Sun, 27 Mar 2022 00:00:00 +0000</pubDate><guid>https://zes1092.github.io/posts/fifteen-million-merits/</guid><description>I haven’t got a speech, I didn’t plan words, I didn’t even try to. I just knew that I had to get here, to stand here and I knew I wanted you to listen; to really listen, not just pull a face like you’re listening, like you do the rest of the time. A face like you’re feeling instead of processing. You pull a face and poke it towards the stage and la-di-da we sing and dance and tumble around and all you see up here, it’s not people, you don’t see people up here, it’s all fodder.</description><content type="html">&lt;blockquote>
&lt;p>I haven’t got a speech, I didn’t plan words, I didn’t even try to. I just knew that I had to get here, to stand here and I knew I wanted you to listen; to really listen, not just pull a face like you’re listening, like you do the rest of the time. A face like you’re feeling instead of processing. You pull a face and poke it towards the stage and la-di-da we sing and dance and tumble around and all you see up here, it’s not people, you don’t see people up here, it’s all fodder. And the faker the fodder is the more you love it because fake fodder’s the only thing that works anymore, fake fodder is all that we can stomach — actually not quite all. Real pain, real viciousness, that we can take. Yeah, stick a fat man up a pole and we’ll laugh ourselves feral cause we’ve earned the right, we’ve done cell time and he’s slacking the scum so ha ha ha at him. Cause we’re so out of our minds with desperation we don’t know any better. All we know is fake fodder and buying shit. That’s how we speak to each other, how we express ourselves is buying shit. I have a dream? The peak of our dreams is a new hat for our doppel, a hat that doesn’t exist. It’s not even there, we buy shit that’s not even there. Show us something real and free and beautiful, you couldn’t. It’d break us, we’re too numb for it, our minds would choke. There’s only so much wonder we can bear, that’s why when you find any wonder whatsoever you dole it out in meager portions, and only then til it’s augmented and packaged and pumped through ten thousand pre-assigned filters, til it’s nothing more than a meaningless series of lights, while we ride day-in, day-out — going where? Powering what? All tiny cells in tiny screens and bigger cells in bigger screens and fuck you. Fuck you, that’s what it boils down to is fuck you. Fuck you for sitting there and slowly knitting things worse. Fuck you and your spotlight and your sanctimonious faces and fuck you all, for taking the one thing I ever came close to anything real about anything. For oozing around it and crushing it into a bone, into a joke, one more ugly joke in a kingdom of millions and then fuck you. Fuck you for happening. Fuck you for me, for us, for everyone, fuck you&lt;/p>
&lt;/blockquote></content></item><item><title>the stage is yours</title><link>https://zes1092.github.io/posts/the-stage-is-yours/</link><pubDate>Sat, 26 Mar 2022 00:00:00 +0000</pubDate><guid>https://zes1092.github.io/posts/the-stage-is-yours/</guid><description>Social media has completely taken over our lives to the point where it&amp;rsquo;s a second reality.
It&amp;rsquo;s all a performance.
No other generation has to pretend to know what they&amp;rsquo;re talking about. Today our entertainment is people&amp;rsquo;s lives. Where attention is literally a currency. I understand trying to take accountabiliy for your actions but everyone&amp;rsquo;s trying so hard to be on the right side of history that they sound like robots.</description><content type="html"><![CDATA[<p>Social media has completely taken over our lives to the point where it&rsquo;s a second reality.</p>
<blockquote>
<p>It&rsquo;s all a performance.</p>
</blockquote>
<p>No other generation has to pretend to know what they&rsquo;re talking about. Today our entertainment is people&rsquo;s lives. Where attention is literally a currency. I understand trying to take accountabiliy for your actions but everyone&rsquo;s trying so hard to be on the right side of history that they sound like robots. Deciding what is right from wrong. They only do it to appear morally superior to people online.</p>
<p>I&rsquo;ve realised being away from people how much I missed it. When you speak to someone face to face, suddenly all that noise you forget about when you&rsquo;re in the real world talking to real people. People drop their act when you talk to them face to face. I&rsquo;ve realised how much I say in conversations not because it&rsquo;s truthful or it&rsquo;s funny but because how people are going to perceive me if I tell them. We want to seem special. We want to be cooler than we really are. But you&rsquo;ll notice as soon as you say something embarassing. As soon as you actually open up to someone. Their guard goes away. Now they&rsquo;re not performing. You can speak to them like they really are. When in reality, I&rsquo;m guilty of all the stuff I&rsquo;m criticising. I&rsquo;m completely addicted to social media. And I care too much what people think about me.</p>
]]></content></item><item><title>COMP4121</title><link>https://zes1092.github.io/posts/comp4121/</link><pubDate>Tue, 22 Mar 2022 00:00:00 +0000</pubDate><guid>https://zes1092.github.io/posts/comp4121/</guid><description>Stats Expectation and Variance of a Random Variable The expected value of a random variable is its mean. Assuming that the expected value converges, the expected value can be calculated as shown below.
Discrete random variable Continuous random variable $E(X) = \sum_{i = 1}^{\infty} v_i \cdot p_i$ $E(X) = \int_{-\infty}^{\infty}x \cdot f(x) dx$ The variance of a random variable is defined as $V(X) = E(X - E(X))^2$ assuming that both expectations involved are finite; the standard deviation of a random variable $X$ is given by $\sigma = \sqrt{V(X)}$.</description><content type="html"><![CDATA[<h2 id="stats">Stats</h2>
<h3 id="expectation-and-variance-of-a-random-variable">Expectation and Variance of a Random Variable</h3>
<p>The <strong>expected value</strong> of a random variable is its mean. Assuming that the expected value converges, the expected value can be calculated as shown below.</p>
<table>
<thead>
<tr>
<th>Discrete random variable</th>
<th>Continuous random variable</th>
</tr>
</thead>
<tbody>
<tr>
<td>$E(X) = \sum_{i = 1}^{\infty} v_i \cdot p_i$</td>
<td>$E(X) = \int_{-\infty}^{\infty}x \cdot f(x) dx$</td>
</tr>
</tbody>
</table>
<p>The <strong>variance</strong> of a random variable is defined as $V(X) = E(X - E(X))^2$ assuming that both expectations involved are finite; the standard deviation of a random variable $X$ is given by $\sigma = \sqrt{V(X)}$.</p>
<h3 id="simple-inequalities">Simple inequalities</h3>
<p>$$1 + x \leq e^x \text{ for all } x \in \mathbb{R}$$
$$\left(1 - \frac{1}{n}\right)^n \leq \frac{1}{e} \leq \left(1 - \frac{1}{n} \right)^{n - 1} \text{ for all } n \in \mathbb{N}$$</p>
<h3 id="probability-inequalities">Probability Inequalities</h3>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>The Markov Inequality</strong></td>
<td>Let $X &gt; 0$ be a non-negative random variable. Then for all $t &gt; 0$, $$P(X \geq t) \leq \frac{E(X)}{t}$$</td>
</tr>
<tr>
<td><strong>Chebyshev Inequality</strong></td>
<td>Let $X &gt; 0$ be a random variable with the expected value $\mu = E(X)$ and standard deviation $\sigma = \sqrt{E((X - \mu)^2)}$. Then for all $\lambda &gt; 0$, $$P(| X - \mu | \geq \lambda \sigma) \leq \frac{1}{\lambda^2}$$</td>
</tr>
<tr>
<td><strong>Chernoff Bound</strong></td>
<td>Let $X = \sum_{k = 1}^{n} X_k$, where $X_k, 1 \leq k \leq n$, are independent Bernoulli trials with the probability of success $P(X_k = 1) = p_k$, where $0 &lt; p_k &lt; 1$. Thus, $\mu = E(X) = \sum_{k = 1}^{n} p_k$. Let $\sigma &gt; 0$ be any positive real. Then, $$P(X &gt; (1 + \sigma) \mu) &lt; \left( \frac{e^{\sigma}}{(1 + \sigma)^{1 + \sigma}}\right)^{\mu}$$</td>
</tr>
</tbody>
</table>
<h2 id="order-statistics-quickselect">Order Statistics (QuickSelect)</h2>
<p><strong>Can we find the $i^{th}$ largest or smallest item in linear time?</strong></p>
<h3 id="non-deterministic-algorithm">Non-Deterministic Algorithm</h3>
<p>In the quicksort algorithm, we note that after a partition, the pivot element ends up being in its correct index. Therefore, we can perform a combination of partitioning and binary search to find the item at the $i^{th}$ index.</p>
<p>For example, we partition first using a random pivot, and as a result we will know the index of our pivot.
If the pivot is index $i$, we&rsquo;ve found the element.
Else if the pivot is at an index greater than $i$, then we partition the smaller side, else we partition the bigger side and continue until we&rsquo;ve found the $i^{th}$ element.</p>
<pre><code class="language-py"># Implementation of rand-select

def partition(A: list[int], lo: int, hi: int) -&gt; int:
    # Partition the array A[lo..hi] and return partition index
    i = lo - 1
    pivot = A[hi]
    for j in range(lo, hi):
        if A[j] &lt;= pivot:
            i += 1
            A[i], A[j] = A[j], A[i]
    A[i + 1], A[hi] = A[hi], A[i + 1]
    return i + 1


def rand_select(A: list[int], i: int, lo: int, hi: int) -&gt; int:
    # Return the ith largest index in A
    if lo &lt;= hi:
        pi = partition(A, lo, hi)
        if i &lt; pi:
            return rand_select(A, i, lo, pi - 1)
        return rand_select(A, i, pi + 1, hi)
    return A[hi]
</code></pre>
<h3 id="runtime">Runtime</h3>
<p>The runtime can be represented through the recurrence relation $T(n) = T\left( \frac{n}{2} \right) + O(n)$ which results in a $O(n)$ runtime. However, it can be analysed more in-depth statistically.</p>
<h4 id="worst-case">Worst Case</h4>
<p>The worst case runtime is $\Theta(n^2)$ which happens when the smallest or largest element is picked as the pivot - resulting in an <em>unbalanced partition</em>.</p>
<h4 id="average-case">Average Case</h4>
<p>However (assuming all elements are <strong>distinct</strong>), let us call a partition a <em>balanced partition</em> if the ratio between the ratio smaller side and larger side is less than 9 (9 is arbitrary, any small number &gt; 2 would do).
Then the probability of having a balanced partition is 1 - (chance of choosing smallest 1/10 or biggest 1/10) = 1 - 2/10 = 8/10.</p>
<p>Then let us find the expected number of partitions between two consecutive balanced partitions.
In general, the probability that you need $k$ partitions to end up with another balanced partition is $\left( \frac{2}{10} \right)^{k - 1} \cdot \frac{8}{10}$.</p>
<p>Thus, the expected number of partitions between two balanced partitions is</p>
<p>$$
\begin{align*}
E
&amp;= 1 \cdot \frac{8}{10} + 2 \cdot \left( \frac{2}{10} \right) \cdot \frac{8}{10} + 3 \cdot \left( \frac{2}{10} \right)^2 \cdot \frac{8}{10} + &hellip; \\
&amp;= \frac{8}{10} \cdot \sum_{k = 0}^{\infty}(k + 1) \left( \frac{2}{10} \right)^k \\
&amp;= \frac{8}{10}S.
\end{align*}
$$</p>
<ul>
<li>
<p>To find $S$, note that</p>
<p>$$\sum_{k = 0}^{\infty} q^k = \frac{1}{1 - q}.$$</p>
<p>By differentiating both sides with respect to $q$ we get</p>
<p>$$\sum_{q = 1}^{\infty} k q^{k - 1} = \frac{1}{(1 - q)^2}.$$</p>
<p>Substituting $q = \frac{2}{10}$ we get that $S = \left(\frac{10}{8} \right)^2$.</p>
</li>
</ul>
<p>Therefore,</p>
<p>$$E = \frac{8}{10} \cdot \left( \frac{8}{10} \right)^2 = \frac{5}{4}.$$</p>
<p>And so there are only 5/4 partitions between two balanced partitions.</p>
<ul>
<li>Note after 1 <em>balanced partition</em>, the size of the array is $\leq 9/10 n$, after the second <em>balanced partition</em>, it is $\leq (9/10)^2n$ and so on.</li>
</ul>
<p>Therefore, the total <strong>average</strong> (expected) run time satisfies</p>
<p>$$
\begin{align*}
T(n)
&amp;&lt; 5/4n + 5/4 \left( \frac{9}{10} \right)n + 5/4 \left( \frac{9}{10} \right)^2 n + 5/4 \left( \frac{9}{10} \right)^3 n + &hellip; \\
&amp;= \frac{5/4 n}{1 - \frac{9}{10}} \\
&amp;= 12.5n.
\end{align*}
$$</p>
<p>Overall, the expected runtime of this algorithm is linear.</p>
<h2 id="database-access">Database access</h2>
<p>Assume that $n$ processes want to access a database, and that the time $t$ is discrete.
If two processes simultaneously request access, there is a conflict and all processes are locked out of access.</p>
<p>Assume that processes cannot communicate with each other on when to access.
One possible for a process to determine if it should access the database at time $t$ is to &ldquo;request access&rdquo; with probability $p$ and &ldquo;do not request access&rdquo; with probability $(1 - p)$.</p>
<p><strong>What should $p$ be to maximise the probability of a successful access to the database for a process at any instant $t$?</strong></p>
<h3 id="efficient-selection-of-p">Efficient selection of p</h3>
<p>The probability of success of process $i$ at any instant $t$ is</p>
<p>$$P(S(i, t)) = p(1 - p)^{n - 1},$$</p>
<p>because a process $i$ requests access with probability $p$ and the probability that no other process has requested access is $(1 - p)^{n - 1}$.
The extreme points of this is found by solving</p>
<p>$$\frac{d}{dp}P(S(i, t)) = (1 - p)^{n - 1} - p(n - 1)(1 - p)^{n - 2} = 0$$</p>
<p>which gives $p = 1/n$, which gives a probability of success of</p>
<p>$$P(S(i, t)) = p(1 - p)^{n - 1} = \frac{1}{n} \left( 1 - \frac{1}{n} \right)^{n - 1}.$$</p>
<p>However,</p>
<p>$$\lim_{n \rightarrow \infty} \left(1 - \frac{1}{n} \right)^n = e$$</p>
<p>and hence $P(S(i, t)) = \Theta \left( \frac{1}{n} \right)$.
Thus, the probability of failure after $t$ instances is</p>
<p>$$
\begin{align*}
P(\text{failure after $t$ instants})
&amp;= \left( 1 - \frac{1}{n} \left( 1 - \frac{1}{n} \right)^{n - 1} \right)^t \\
&amp;\approx \left( 1 - \frac{1}{e n}\right)^t
\end{align*}
$$</p>
<p>We observe that</p>
<table>
<thead>
<tr>
<th>P(failure after $t = en$ instances</th>
<th>P(failure after $t = en \cdot 2 \ln n$ instances</th>
</tr>
</thead>
<tbody>
<tr>
<td>$$\left( 1 - \frac{1}{en}\right)^{en} \approx \frac{1}{e}$$</td>
<td>$$\left(1 - \frac{1}{en} \right)^{en \cdot 2 \ln n} \approx \frac{1}{n^2}$$</td>
</tr>
</tbody>
</table>
<p>Thus, a small increase in the number of time instants, from $en$ to $en \cdot 2 \ln n$ caused a dramatic reduction in the probability of failure.</p>
<p>After $en \cdot 2 \ln n$ instances, the probability of failure of each process $\leq 1/n^2$ and since there are $n$ processes, then the probability that at least one process failed is $\leq 1/n$.
Thus after $en \cdot 2 \ln n$ instances all processes succeeded to access the database with probability at least $1 - 1/n$.</p>
<h3 id="comparison-with-centralised-algorithm">Comparison with centralised algorithm</h3>
<p>If the processes could communicate, then it would take $n$ instances for all of them to access the database.</p>
<p>If they can&rsquo;t communicate, then the above method will allow them to access the database with probability $1 - 1/n$ time, which is larger only by a relatively small factor of $2e \ln n$.</p>
<h2 id="skip-lists">Skip Lists</h2>
<p>A skip list is a probabilistic data structure that functions similarly to a binary search tree.</p>
<pre><code class="language-py"># Example structure of a skip list

[H]--------------------------[35]----------------[T]
[H]----------------[21]------[35]----------------[T]
[H]------[12]------[21]-[24]-[35]------[55]------[T]
[H]-[02]-[12]-[17]-[21]-[24]-[35]-[43]-[55]-[62]-[T]
</code></pre>
<h3 id="operations">Operations</h3>
<ul>
<li>
<p><strong>Search of $k$</strong></p>
<ol>
<li>Start from the highest level of head H and go as far right without exceeding $k$</li>
<li>Drop one level down and repeat the procedure using lower level links until you find $k$</li>
</ol>
</li>
<li>
<p><strong>Insertion of $k$</strong></p>
<ol>
<li>Search for the correct location</li>
<li>Toss a coin until you get a head, and count the number of tails $t$ you got</li>
<li>Insert $k$ and link it at levels $0 - t$ from the bottom up</li>
</ol>
</li>
<li>
<p><strong>Deletion</strong></p>
<p>Deleting an element is just like in a standard doubly linked list</p>
</li>
</ul>
<h3 id="analysis">Analysis</h3>
<h4 id="expected-levels">Expected Levels</h4>
<p>The probability of getting $i$ consecutive tails when flipping a coin $i$ times is $1/2^i$.
Thus, an $n$ element Skip List has on average $n/2^i$ elements with links on level $i$.
Since an element has links only on levels $0 - i$ with probability $1/2^{i + 1}$, the total <strong>expected</strong> number of link levels per element is</p>
<p>$$\sum_{i = 0}^{\infty} \frac{i + 1}{2^{i + 1}} = \sum_{i = 1}^{\infty} \frac{i}{2^i} = 2.$$</p>
<p>Let $\#(i)$ be the number of elements on level $i$.</p>
<p>Then, $E[\#(i)] = \frac{n}{2^i}$, and by the Markov inequality, the probability of having at least one element at level $i$ satisfies</p>
<p>$$P(\#(i) \geq 1) \leq \frac{E[\#(i)]}{1} = \frac{n}{2^i}.$$</p>
<p>Thus, the probability to have an element on level $2 \log n$ is smaller than $n/2^{2 \log n} = 1/n.$</p>
<p>More generally, the probability to have an element (be nonempty) on level $k \log n$ $&lt; n /2^{k \log n} = 1/n^{k - 1}$.
The expected value $E(k)$ such that $k$ is the lowest integer so that the number of levels is $\leq k \log n$ is</p>
<p>$$E(k) \leq \sum_{k = 1}^{\infty} \frac{k}{n^{k - 1}} = \left( \frac{n}{n - 1} \right)^2.$$</p>
<p>Thus, the expected number of levels is barely larger than $\log n$.</p>
<h4 id="expected-search-per-level">Expected search per level</h4>
<p>Thus, the expected number of elements between any two consecutive elements with a link on level $i + 1$ which have links only up to level $i$ is smaller than</p>
<p>$$\frac{0}{2} + \frac{1}{2^2} + \frac{2}{2^3} + \frac{3}{2^4} + &hellip; = 1.$$</p>
<p>So once on level $i$, on average we will have to inspect only two elements on that level before going to a lower level.</p>
<h4 id="search-time-complexity">Search Time Complexity</h4>
<p>On average, levels $&lt; 2 \log n$, and 2 elements are visited per level.
Therefore, on average, the search will be in time $O(4 \log n) = O(\log n)$.</p>
<h4 id="space-complexity">Space Complexity</h4>
<p>For an element on levels $0 - i$, we store $O(i + 1)$ pointers, and expected number of elements with highest link on level $i$ is $O(n/2^{i + 1})$. Thus, total expected space for is</p>
<p>$$O \left( \sum_{i = 0}^{\infty}2(i + 1) \frac{n}{2^{i + 1}}\right) = O \left( 2n \sum_{i = 0}^{\infty} \frac{i + 1}{2^{i + 1}} \right) = O(4n) = O(n).$$</p>
<h2 id="kargers-min-cut-algorithm">Karger&rsquo;s Min Cut Algorithm</h2>
<p>Given a graph $G = (V, E)$, Karger&rsquo;s Min Cut algorithm finds a cut $T$ that partitions vertices $V$ into two non empty disjoint subsets $X$ and $Y$, with the lowest capacity of edges which have one edge in $X$ and the other in $Y$.</p>
<p>A deterministic way to solve this is through max flow from one vertex to all other vertices, however this runs in $O(|V|^4)$.</p>
<h3 id="procedure">Procedure</h3>
<h4 id="contraction">Contraction</h4>
<p>The algorithm makes use of contracting edges in a graph.
To contract an edge $e(u, v)$, fuse $u$ and $v$ into a single vertex $[uv]$ and replace edges $e(u, x)$ and $e(v, x)$ with a single edge $e([uv], x)$ of weight $w([uv], x) = w(u, x) + w(v, x)$.
The obtained graph after this is called $G_{uv}$.</p>
<h3 id="claims">Claims</h3>
<p>After collapsing $u$ and $v$ into a single vertex</p>
<ul>
<li>If $u$ and $v$ belong to the <strong>same side of a min cut</strong>, the capacity of the min cut in $G_{uv}$ is the same as that of $G$.</li>
<li>If $u$ and $v$ belong to <strong>opposite sides of a min cut</strong>, the capacity of the min cut in $G_{uv}$ is larger or equal to the capacity of the min cut in $G$.</li>
</ul>
<p>Therefore,</p>
<ul>
<li>
<p>Let $T_1 = (X_1, Y_1)$ be a min cut in $G_{uv}$</p>
</li>
<li>
<p>Split $[uv]$ back into $u$ and $v$, but keep them on the same side of the cut $T_1$. This produces a cut $T_2$ in $G$ of the same capacity as the min cut $T_1$ in $G_{uv}$.</p>
<p>Thus, the capacity of the min cut in $G$ can only be smaller than the min cut $T_1$ in $G_{uv}$</p>
</li>
</ul>
<h3 id="algorithm">Algorithm</h3>
<ol>
<li>While there are more than 2 vertices
<ol>
<li>Pick an edge to with probability proportional to the weight of that edge
$$P(e(u, v)) = \frac{w(u, v)}{\sum_{e(p, q) \in E} w(p, q)}$$</li>
<li>Contract the edge, and remove self loops</li>
</ol>
</li>
<li>Take the capacity of that last edge to be the estimate of the capacity of the min cut in $G$</li>
</ol>
<h3 id="theorems">Theorems</h3>
<p>Let $M(G)$ represent the min cut capacity of $G$.</p>
<h4 id="theorem-1">Theorem 1</h4>
<p>The probability that the capacity of a min cut in $G_{uv}$ is larger than the capacity of a min cut in $G$ is smaller than $2/n$ where $n = |V|$.</p>
<p>$$P(M(G_{uv}) &gt; M(G)) &lt; \frac{2}{n}.$$</p>
<p>This is because this probability is less than or equal to the probability that the edge $e(u, v)$ belonged in the set of edges along the min cut $M$.
The probability of the $e(u, v)$ in $M$ is less than or equal to the final min cut capacity divided by the total capacity of the graph (which is equal to $\frac{n}{2}$), resulting in the final probability of $\frac{2}{n}$.</p>
<h4 id="theorem-2">Theorem 2</h4>
<p>If we run edge contraction until there is 1 edge, then the probability $\pi$ that the capacity of that edge is equal to the capacity of the min cut in G is $\Omega \left( \frac{1}{n^2} \right)$.</p>
<p>From the first theorem</p>
<p>$$
\begin{align*}
\pi
&amp;= P(M(G) = M(G_{n-2})) \\
&amp;= \prod_{i = 1}^{n - 2} P(M(G_i) = M(G_{i - 1})) \\
&amp;\leq \left(1 - \frac{2}{n} \right) \left(1-\frac{2}{n-1}\right) \left(1-\frac{2}{n-2}\right) &hellip; \left(1-\frac{2}{3} \right) \\
&amp;= \frac{n - 2}{n} \times \frac{n - 3}{n - 1} \times \frac{n - 4}{n - 2} \times &hellip; \times \frac{1}{3} \\
&amp;= \frac{2}{n(n-1)}.
\end{align*}
$$</p>
<p>Since the contraction runs in $O(n^2)$, and has a $\Omega \left( \frac{1}{n^2} \right)$ chance of being correct, it needs to be run $\Theta(n^2)$ times, resulting in a final runtime of $O(n^4)$ to find the min cut.</p>
<h3 id="kargers-min-cut-refinement">Karger&rsquo;s Min Cut Refinement</h3>
<p>The algorithm can be improved to run in $O(n^2 \log^3 n)$ with the high probability of being correct through a divide and conquer approach.</p>
<p>If after running the contraction algorithm until there is $\lfloor \frac{n}{2} \rfloor$ vertices runs in $O(n^2)$ and the chance of being correct is $\approx 1/4$.
Hence, by running the algorithm until there are $\lfloor \frac{n}{2} \rfloor$ vertices 4 times, and then recursing on those smaller graphs, we have a runtime of</p>
<p>$$T(n) = 4T\left(\frac{n}{2}\right) + O\left(n^2\right) = O(n^2 \log n).$$</p>
<pre><code class="language-py"># Python flavoured pseudo code of the refined algorithm

def karger_refined(G: Graph) -&gt; int:
    V, E = G
    # Base case, return the last and only edge weight
    if len(V) == 2:
        return E[V[0], V[1]]
    
    # Run contraction 4 times and recurse on those 4 new graphs
    min_cuts = [karger_refined(contract(G)) for _ in range(4)]
    return min(min_cuts)
</code></pre>
<p>Let $p(n) = P(\text{success for a graph of size $n$})$, then</p>
<p>$$
\begin{align*}
p(n)
&amp;= 1 - P(\text{failure on one branch})^4 \\
&amp;= 1 - (1 - P(\text{success on one branch}))^4 \\
&amp;= 1 - \left( 1 - \frac{1}{4}p \left(\frac{n}{2}\right)\right)^4 \\
&amp;&gt; p\left(\frac{n}{2}\right) - \frac{3}{8}p\left(\frac{n}{2}\right)^2 \\
&amp;&gt; \frac{1}{log(n)}.
\end{align*}
$$</p>
<p>If we run our algorithm $(\log n)^2$ times, the probability we are correct $\pi$ is</p>
<p>$$\pi = 1 - \left(1 - \frac{1}{\log n} \right)^{(\log n)^2}$$</p>
<p>However, since for all reasonably large $k$, $(1 - 1/k)^k \approx e^{-1}$.
As a result,</p>
<p>$$\pi \approx 1 - e^{-\log n} = 1 - 1/n.$$</p>
<p>Hence, if we run <code>karger_refined</code> $(\log n)^2$ times, we have a probability of being correct $1 - 1/n$, with a runtime of</p>
<p>$$O\left(n^2 \log^3 n \right) \lt\lt O(\left(n^4\right).$$</p>
<h2 id="randomised-hashing">Randomised Hashing</h2>
<p>If the hash function can be analysed, and a sequence of worst keys is chosen, then a lookup in a hash table can take $O(n)$, though ideally we want to have $O(1)$.</p>
<h3 id="universal-hashing">Universal Hashing</h3>
<p>Let $H$ be a finite collection of hash functions that map a given universe $U$ of keys into the smaller range {0 .. m - 1}.
$H$ is said to be <strong>universal</strong> if for each pair of distinct keys $x, y \in U$, the number of hash functions $h \in H$ for which $h(x) = h(y)$ is $\frac{|H|}{m}$.</p>
<p>Assume that a family of hash functions $H$ is universal, and we are hashing $n$ keys into a hash table of size $m$.
Let $C_x$ be the total number of collisions involving key $x$, then the expected value $E[C_x]$ satisifies</p>
<p>$$E[C_x] = \frac{n - 1}{m}.$$</p>
<h4 id="designing-a-universal-family-of-hash-functions">Designing a universal family of hash functions</h4>
<ul>
<li>Choose the size of the hash table $m$ to be a prime number</li>
<li>Let $r$ be such that the size $|U|$ of the universe of all keys satisifies $m^r \leq |U| \leq m^{r+1}$, i.e. $r = \lfloor \log_m |U|\rfloor$</li>
<li>Hence, we can represent each key $x$ in base $m$ where
$$\vec{x} = \langle x_0, x_1, &hellip;, x_r\rangle \text{ and } x = \sum_{i=0}^{r}x_i m^i$$</li>
<li>Let $\vec{a} = \langle a_0, a_1, &hellip;, a_r \rangle$ be a vector of $r + 1$ <strong>randomly chosen</strong> elements from the set $\{0, 1, &hellip;, m - 1 \}$</li>
<li>Define a corresponding hash function $h_{\vec{a}}(x) = \left( \sum_{i=0}^{r} x_i a_i \right) \mod m$</li>
</ul>
<h4 id="proving-universality">Proving universality</h4>
<p>Assume $x, y$ are two distinct keys. Then for there to be a hash collision,</p>
<p>$$
\begin{align*}
h_{\vec{a}}(x) = h_{\vec{a}}(y)
&amp;\Leftrightarrow \sum_{i=0}^{r}x_ia_i = \sum_{i=0}^{r}y_ia_i \mod m \\
&amp;\Leftrightarrow \sum_{i=0}^{r}(x_i - y_ia_i) = 0 \mod m
\end{align*}
$$</p>
<p>Since $x \neq y$ there exits $0 \leq k \leq r$ such that $x_k \neq y_k$.
Assume that $x_0 \neq y_0$, then</p>
<p>$$(x_0 - y_0)a_0 = - \sum_{i=1}^{r}(x_i - y_i)a_i \mod m$$</p>
<p>Since $m$ is a prime, every non-zero element $z \in \{0, 1, &hellip;, m - 1\}$ has a multiplicative inverse $z^{-1}$, such that $z \cdot z^{-1} = 1 \mod m$ and so</p>
<p>$$a_0 = \left( - \sum_{i=0}^{r} (x_i - y_i)a_i \right) (x_0 - y_0)^{-1} \mod m$$</p>
<p>this implies that</p>
<ol>
<li>for any 2 keys $x, y$ such that $x_0 \neq y_0$ and</li>
<li>for any randomly chosen $r$ numbers $a_1, a_2, &hellip;, a_r$</li>
</ol>
<p>there exists <strong>exactly one</strong> $a_0$ such that $h_{\vec{a}}(x) = h_{\vec{a}}(y)$.</p>
<p>Since there are</p>
<ul>
<li>$m^r$ sequences of the form $\langle a_{1}, &hellip;, a_r \rangle$</li>
<li>$m^{r+1}$ sequences of the form $\langle a_0, a_1, &hellip;, a_r \rangle$</li>
</ul>
<p>as a result, the probability to choose a sequence $\vec{a}$ such that $h_{\vec{a}}(x) = h_{\vec{a}}(y)$ is equal to</p>
<p>$$\frac{m^r}{m^{r+1}} = \frac{1}{m}.$$</p>
<p>Thus, the family $H$ is a universal collection of hash functions.</p>
<h4 id="using-universal-family-of-hash-functions">Using universal family of hash functions</h4>
<ol>
<li>Pick $r = \lfloor \log_m |U| \rfloor$ ,so that $m^r \leq |U| \leq m^{r+1}$</li>
<li>For each run, pick a hash function by randomly picking a vector $\vec{a} = \langle a_0, a_1, &hellip;, a_r \rangle$ such that $0 \leq a_i \leq m$, for all $i$,  $0 \leq i \leq r$.</li>
<li>During each run use that function on all keys</li>
</ol>
<h3 id="designing-a-perfect-hash-table">Designing a Perfect Hash table</h3>
<h4 id="first-step">First step</h4>
<p><strong>Given $n$ keys we will be constructing hash tables for size $m &lt; 2n^2$ using universal hashing.
The probability that such a table is collision free will be $&gt; 1/2$</strong></p>
<ol>
<li>Pick the smallest prime $m$, such that $n^2 &lt; m &lt; 2n^2$</li>
<li>Pick a random vector $\vec{a}$ and hash all keys using the corresponding hash function $h_{\vec{a}}$</li>
</ol>
<p>Given $n$ keys, there will be $n \choose 2$ pairs of keys.
By universality of the family of hash functions used, for each pair of keys the probability of collision is $1/m$.
Since $m \geq n^2$ we have $\frac{1}{m} \leq \frac{1}{n^2}$.
Thus, the expected total number of collisions in the table is at most</p>
<p>$${n \choose 2} \frac{1}{m} \leq \frac{n(n - 1)}{2} \frac{1}{n^2} &lt; \frac{1}{2}.$$</p>
<p>Let $X$ be the random variable equal to no. collisions. Then by the Markov Inequality with $t=1$ we get</p>
<p>$$P\{X \geq 1\} \leq \frac{E[X]}{1} &lt; \frac{1}{2}.$$</p>
<p>Thus, the chance of a collision after $k$ hashes $&lt; (1/2)^k$, which rapidly tends to 0.
Consequently, after a few random trial-and-error attempts we will obtain a collision free hash table of size $&lt; 2n^2$.</p>
<p>If $p$ is the probability of a collision, then the expected number of trials $E[N]$ before we hit a collision free hash table of size $2n^2$ is</p>
<p>$$
\begin{align*}
E[N]
&amp;= 1(1 - p) + 2p(1 - p) + 3p^2(1 - p) + &hellip; \\
&amp;= (1 - p)(1 + 2p + 3p^2 + &hellip;) \\\
&amp;= \frac{1}{1 - p} \\
&amp;&lt; 2.
\end{align*}
$$</p>
<h4 id="second-step">Second step</h4>
<p><strong>Choose $M$ to be the smallest prime number $&gt; n$</strong></p>
<p>Thus, $n \leq m \leq 2n$.
Produce a hash table of size $M$ again by choosing randomly from a universal family of hash funtions.
Assume that a slot $i$ of this table has $n_i$ many elements.
Hash these $n_i$ elements into a secondary hash table of size $m_i &lt; 2n_i^2$.
We have to guarantee that the sum total of sizes of all secondary hash tables, i.e., $\sum_{i=1}^{M}m_i$ is linear in $n$.
Note ${n_i \choose 2}$ is the number of collisions at $n_i$ and</p>
<p>$${n_i \choose 2} = \frac{n_i(n_i - 1)}{2} = \frac{n_i^2}{2} - \frac{n_i}{2}.$$</p>
<p>Therefore the total number of collisions in the hash table is $\sum_{i=1}^{M} {n_i \choose 2}$, and since the expected value of collision with universal hashing is $1/M$,</p>
<p>$$
\begin{align*}
E\left[ \sum_{i=1}^{M} {n_i \choose 2} \right]
&amp;= {n \choose 2}\frac{1}{M} \\
&amp;= \frac{n(n - 1)}{2M} \\
E\left[ \sum_{i=1}^{M} n_i^2 \right]
&amp;= 2E\left[ \sum_{i=1}^{M} {n_i \choose 2} \right] + n
\end{align*}
$$</p>
<p>Thus,</p>
<p>$$E\left[ \sum_{i=1}^{M} n^2_i \right] \leq \frac{n(n-1)}{n} + n = 2n - 1 &lt; 2n.$$</p>
<p>Applying the Markov Inequality to find the probability we have more than $4n$ items in our hash table, we obtain</p>
<p>$$P \left\{ \sum_{i=1}^{M} n_i^2 &gt; 4n \right\} \leq \frac{E\left[ \sum_{i=1}^{M} n_i^2 \right]}{4n} &lt; \frac{2n}{4n} = \frac{1}{2}$$</p>
<p>Thus, after a few attempts we will produce a hash table of size $M &lt; 2n$ for which $\sum_{i=1}^{M} &lt; 4n$, and if we choose primes $m_i &lt; 2n_i^2$ then $\sum_{i=1}^{M} m_i &lt; 8n$.
In this way the size of the primary hash table plus the sizes of all secondary hash tables satisfies</p>
<p>$M + \sum_{i=1}^{M}m_i &lt; 2n + 8n = 10n.$</p>
<h2 id="gaussian-annulus-random-projection-and-johnson-lindenstrauss-lemmas">Gaussian Annulus, Random Projection and Johnson Lindenstrauss Lemmas</h2>
<h3 id="generating-random-points-in-d-dimensional-spaces">Generating random points in d-dimensional spaces</h3>
<p>Let us consider a Gaussian random variable $X$ with a zero mean ($E[X] = \mu = 0$) and variance $V[X] = v = 1/2\pi$, then its density is given by</p>
<p>$$f_X(x) = \frac{1}{\sqrt{2\pi v}}e^{-\frac{x^2}{2v}} = e^{-\pi x^2}$$</p>
<p>Assume that we use such $X$ to generate independently the coordinates $\langle x_1, &hellip;, x_d \rangle$ of a random vector $\vec{x}$ from $\mathbb{R}^d$.
Then $E[X^2] = E[(X - E[X])^2] = V[X]$, and $E\left[ \frac{x_1^2 + &hellip; + x_d^2}{d} \right] = dV[X]/d = V[X]$.</p>
<p>As a result, given the length $|x| = \sqrt{x_1^2 + &hellip; + x_d^2}$, the expected value of the square of a the length of $\vec{x}$ is $E[|x|^2] = d/2\pi$. So, on average, $|x| \approx \frac{\sqrt{d}}{\sqrt{2\pi}} = \Theta(\sqrt{d})$, and if $d$ is large, then this is true with a high probability.</p>
<p>If we choose 2 points independently, then</p>
<p>$$E[\langle x, y \rangle] = E[x_1 y_1 + &hellip; + x_d y_d] = d E[XY] = d E[X] E[Y] = 0.$$</p>
<p>Hence, the expected value of the scalar product of any 2 vector with randomly chosen coordinates is zero.</p>
<p>Hence, vectors with randomly chosen coordinates:</p>
<ul>
<li><strong>have approximate the same length $\Theta(\sqrt{d})$</strong></li>
<li><strong>any 2 such vectors are likely to be almost orthogonal</strong></li>
</ul>
<h3 id="higher-dimensional-balls">Higher Dimensional Balls</h3>
<p>Most of the volume of a high dimensional ball is near:</p>
<ul>
<li>Any of its equators (between two close parallel hyper-planes symmetric with respect to the center).
<ul>
<li>(Insert lots of math).
The ratio between a slice of the sphere $A$ that lies above the hyperplane $x_1 = \frac{c}{\sqrt{d - 1}}$ for some constant $c$, and the whole hemisphere satisifies
$$
\frac{A}{H} &lt; \frac{
V(d - 1)\frac{
e^{\frac{-c^2}{2}}
}{
c \sqrt{d - 1}
}
}{
V(d - 1) \frac{
1
} {
2 \sqrt{d - 1}
}
}
= \frac{2}{c}e^{-\frac{c^2}{2}}
$$</li>
</ul>
</li>
<li>It&rsquo;s surface (if we have a ball of radius $r$, and another smaller, of radius $r(1 - \epsilon)$, most of the volume of the bigger ball is in the annulus outside the smaller ball).
<ul>
<li>This is because the area of the smaller ball is $(1 - \epsilon)^d$ and $(1 - \epsilon) &lt; 1$.
Hence, for large values of $d$ this tends to 0 quickly.</li>
</ul>
</li>
</ul>
<h3 id="johnson-lindenstrauss-lemma">Johnson-Lindenstrauss Lemma</h3>
<p>For any $\epsilon$, $0 &lt; \epsilon &lt; 1$, and any integer $n$, assume that $k$ satisfies $k &gt; \frac{3}{\gamma \epsilon^2} \ln n$.
Then for any set of $n$ points given by the vectors $v_1, &hellip;, v_n$ in $\mathbb{R}^d$, with the probability of at least $1 - 3/(2n)$, the random projection $f&rsquo; \mathbb{R}^d \rightarrow \mathbb{R}^k$ has the property that for ALL pairs of points $v_i, v_j$</p>
<p>$$|| f&rsquo;(v_i - v_j)| - |v_i - v_j|| \leq \epsilon | v_i - v_j|.$$</p>
<p>Thus, $f&rsquo;(v)$ &ldquo;almost&rdquo; preserves distances between points given by vectors $v_i$ despite reduction of dimensionality from $d &raquo; k$ to only $k$.</p>
<h3 id="application-of-johnson-lindenstrauss-lemma">Application of Johnson-Lindenstrauss Lemma</h3>
<ul>
<li>Choose $k$ random vectors by choosing each coordinate of every vector using a unit variance Gaussian</li>
<li>Pre-process data by projecting to $k &lt; &lt; d$ dimensional subspace spanned by the $k$ random vectors</li>
<li>For comparing new data with current data, map the new vector $y \in \mathbb{R}^d$ with its projection $f&rsquo;(y) = f(y) / \sqrt{k}$.</li>
<li>Then nearest neighbours of $f&rsquo;(y)$ can be used in hte projected $k$ dimensional space instead of dimension $d &gt; &gt; k$.</li>
</ul>
<h2 id="page-rank">Page Rank</h2>
<p>The Page Rank algorithm aims to solve the problem of how to order webpages.</p>
<h3 id="setup">Setup</h3>
<p>Consider all the webpages $P_i$ on the entire internet as vertices of a directed graph, where a directed edge $P_i \rightarrow P_j$ exists if $P_i$ has a link to $P_j$.</p>
<p>Notation:</p>
<ul>
<li>$\rho(P)$ = the rank of a page (to be assigned)</li>
<li>$\#(P)$ = the number of outgoing links on a web page</li>
</ul>
<p>A web page $P$ should have a high rank only if it is pointed at by many pages $P_i$ which:</p>
<ol>
<li>themselves have a high rank $\rho(P_i)$</li>
<li>and do not point to an excessive number of other web pages, i.e. $\#P(_i)$ is reasonably small.</li>
</ol>
<p>So we want the following system of equations to be satisfied:</p>
<p>$$\left\{\rho(P) = \sum_{P_i \rightarrow P} \frac{\rho(P_i)}{\#(P_i)} \right\}_{P \in WWW}$$</p>
<p>We have a large sparse matrix $G_1$ of size $M \times M$, where $M = |WWW|$</p>
<p>$$
G_1 =
\begin{pmatrix}
g(1, 1) &amp; \ldots &amp; g(1, j) &amp; \ldots &amp; g(1, M) \\
\vdots  &amp; \ddots &amp; \vdots  &amp; \ddots &amp; \vdots  \\
g(i, 1) &amp; \ldots &amp; g(i, j) &amp; \ldots &amp; g(i, M) \\
\vdots  &amp; \ddots &amp; \vdots  &amp; \ddots &amp; \vdots  \\
g(M, 1) &amp; \ldots &amp; g(M, j) &amp; \ldots &amp; g(M, M)
\end{pmatrix}
\
$$</p>
<p>$$
g(i, j) = <br>
\begin{cases}
\frac{1}{\#(P_i)} &amp; \text{ if } P_i \rightarrow P_j \\
0 &amp; \text{otherwise}
\end{cases}
$$</p>
<p>However, because $G_1$ is mostly a sparse matrix, it resembles
$$
G_1 =
\begin{pmatrix}
&amp;   &amp; \vdots      &amp;   &amp;        &amp;   &amp; \vdots      &amp;   &amp;        \\
&amp;   &amp; \vdots      &amp;   &amp;        &amp;   &amp; \vdots      &amp;   &amp;        \\
\ldots &amp; 0 &amp; \frac{1}{k} &amp; 0 &amp; \ldots &amp; 0 &amp; \frac{1}{k} &amp; 0 &amp; \ldots \\
&amp;   &amp; \vdots      &amp;   &amp;        &amp;   &amp; \vdots      &amp;   &amp;        \\
&amp;   &amp; \vdots      &amp;   &amp;        &amp;   &amp; \vdots      &amp;   &amp;        \\
\end{pmatrix}
\
$$</p>
<p>where $k$ is equal to $\#(P_i)$, the number of pages which th epage $P_i$ has links to.
Hence, the system of linear equations can be represented as</p>
<p>$$\mathbf{r}^\intercal = \mathbf{r}^\intercal G_1$$</p>
<p>where</p>
<p>$$\mathbf{r}^\intercal = (\rho(P_1), \rho(P_2), &hellip;, \rho(P_M)).$$</p>
<p>Note that $G_1$ is a markov matrix, and $\mathbf{r}^\intercal$ is a left-hand eigenvector of $G_1$ corresponding to the eigenvalue 1.
Thus, finding ranks of web pages is reduced to finding eigenvectors of $G_1$, which corresponds to the eigenvalue 1.</p>
<p>If we model a random walk on the graph of this matrix, there are 2 issues:</p>
<ol>
<li>
<p>What should we do when we get to a webpage with no outgoing links?</p>
<p><strong>Solution:</strong>
Jump to a randomly chosen webpage when a node with no outgoing links.</p>
<p>I.e. the first row in $G_1$ is a dangling page, with no outgoing pages.
$G_2$ fixes this by making it point to all pages with equal probability.
Such a matrix is <strong>row stochastic</strong>, meaning that each row sums up to 1.</p>
<p>$$
G_1 =
\begin{pmatrix}
&amp;   &amp; \vdots             &amp;   &amp;        &amp;   &amp; \vdots             &amp;   &amp;        \\
\ldots &amp; 0 &amp; 0                  &amp; 0 &amp; \ldots &amp; 0 &amp; 0                  &amp; 0 &amp; \ldots \\
&amp;   &amp; \vdots             &amp;   &amp;        &amp;   &amp; \vdots             &amp;   &amp;        \\
\ldots &amp; 0 &amp; \frac{1}{\#(P_i)} &amp; 0 &amp; \ldots &amp; 0 &amp; \frac{1}{\#(P_i)} &amp; 0 &amp; \ldots \\
&amp;   &amp; \vdots             &amp;   &amp;        &amp;   &amp; \vdots             &amp;   &amp;        \\
\end{pmatrix}
\\
\\
G_2 =
\begin{pmatrix}
&amp;             &amp; \vdots             &amp;             &amp;         &amp;             &amp; \vdots             &amp;             &amp;        \\
\ldots &amp; \frac{1}{M} &amp; \frac{1}{M}        &amp; \frac{1}{M} &amp; \ldots  &amp; \frac{1}{M} &amp; \frac{1}{M}        &amp; \frac{1}{M} &amp; \ldots \\
&amp;             &amp; \vdots             &amp;             &amp;         &amp;             &amp; \vdots             &amp;             &amp;        \\
\ldots &amp; 0           &amp; \frac{1}{\#(P_i)} &amp; 0           &amp; \ldots  &amp; 0           &amp; \frac{1}{\#(P_i)} &amp; 0           &amp; \ldots \\
&amp;             &amp; \vdots             &amp;             &amp;         &amp;             &amp; \vdots             &amp;             &amp;        \\
\end{pmatrix}
\
$$</p>
</li>
<li>
<p>If $T$ is the walk length, then as $T \rightarrow \infty$, the values $N(P)/T$ should converge.
This becomes an issue if there are disconnected graphs or if the graph is bipartite (and the probability of being in one side depends if the path length is odd or even).</p>
<p><strong>Solution:</strong>
Randomly jump to a new page after some time.</p>
<p>This transformation does not change the rows corresponding to dangling webpages: $\alpha / M + (1 - \alpha) / M = 1/M$
$$
G =
\begin{pmatrix}
&amp;                      &amp; \vdots                                    &amp;                      &amp;         &amp;                      &amp; \vdots                                    &amp;                      &amp;        \\
\ldots &amp; \frac{1}{M}          &amp; \frac{1}{M}                               &amp; \frac{1}{M}          &amp; \ldots  &amp; \frac{1}{M}          &amp; \frac{1}{M}                               &amp; \frac{1}{M}          &amp; \ldots \\
&amp;                      &amp; \vdots                                    &amp;                      &amp;         &amp;                      &amp; \vdots                                    &amp;                      &amp;        \\
\ldots &amp; \frac{1 - \alpha}{M} &amp; \frac{\alpha}{\#(P_i)} + \frac{1 - \alpha}{M} &amp; \frac{1 - \alpha}{M} &amp; \ldots  &amp; \frac{1 - \alpha}{M} &amp; \frac{\alpha}{\#(P_i)} + \frac{1 - \alpha}{M} &amp; \frac{1 - \alpha}{M} &amp; \ldots \\
&amp;                      &amp; \vdots                                    &amp;                      &amp;         &amp;                      &amp; \vdots                                    &amp;                      &amp;        \\
\end{pmatrix}
\
$$</p>
</li>
</ol>
<p>These two solutions allow the ranks to converge, because the model works like a well behaved Markov Chain.</p>
<p>To implement the first solution:</p>
<p>Let $d$ be 1 at positions $i$ which correspond to dangling webpages and 0 elsewhere</p>
<p>$$\mathbf{d}^\intercal = (0 \ &hellip; \ 0 \ 1 \ 0 \ &hellip; \ 0 \ 1 \ 0 \ &hellip; \ 0 \ 1 \ 0 \ &hellip; \ 0)$$</p>
<p>Let $\mathbf{e}$ be 1 everywhere: $\mathbf{e}^\intercal = (1 \ 1 \ &hellip; \ 1)$.</p>
<p>Then
$$G_2 = G_1 + \frac{1}{M} \mathbf{d} \mathbf{e}^\intercal$$</p>
<p>To implement the second solution as well, we get $G$ as:</p>
<p>$$G = \alpha G_2 + \frac{1 - \alpha}{M} \mathbf{e} \mathbf{e}^\intercal = \alpha \left( G_1 + \frac{1}{M} \mathbf{d} \mathbf{e}^\intercal \right) + \frac{1 - \alpha}{M} \mathbf{e} \mathbf{e}^\intercal$$</p>
<p>$G$ is no longer sparse, but the vector matrix product $\mathbf{x}^\intercal G$ for vectors $\mathbf{x}$ whose coordinates sum up to 1 can be decomposed as:</p>
<p>$$\mathbf{x}^\intercal = \alpha \mathbf{x}^\intercal G_1 + \frac{1}{M} \left(1 - \alpha (1 - \mathbf{x}^\intercal \mathbf{d}) \right) \mathbf{e}^\intercal$$</p>
<h3 id="markov-chains-discrete-time-markov-processes">Markov Chains (Discrete Time Markov Processes)</h3>
<p>A (finite) Markov Chain is given by a finite set of states $S = \{P_i\}_{i \leq M}$ and by a row stochastic matrix $G$.
The process can start at $t = 0$ in any of its states and continue its evolution by going at every discrete moment of time from its present state to another randomly chosen state.</p>
<p>The model of the random walk on the graph is an example of a Markov Chain:</p>
<ul>
<li>States are &ldquo;being at a webpage $P_i$&rdquo;, so we have in total $M$ states, one for each web page $P_i$, $1 \leq i \leq M$.</li>
<li>We start from a randomly chosen starting web page.</li>
<li>Thus, $q^{(0)}(i) = \frac{1}{M}$ for all $i$, because all pages are equally likely to be the starting page.</li>
<li>If a webpage $P_i$ is not a dangling webpage, follow a link on the page $P_i$ which points to another webpage $P_j$ with prob $\frac{\alpha}{\#(P_i)}$, or jump directly to a page $P_j$ with probability $\frac{1 - \alpha}{M}$.
<ul>
<li>Hence if a page $P_i$ does not point to a page $P_j$ then $g_{i, j} = \frac{1 - \alpha}{M}$.</li>
</ul>
</li>
<li>If $P_i$ is a dangling page then $g_{i, j} = \frac{1}{M}$ for every page $P_j$ (including the same page $P_i$).</li>
</ul>
<h4 id="general-markov-chains">General Markov Chains</h4>
<ul>
<li>The Google matrix induces a strongly connected graph (as there is a directed edge between any two vertices), and so is <strong>irreducible</strong>.</li>
<li>The Google matrix ix <strong>aperiodic</strong>
<ul>
<li>A state $P_i$ in a Markov chain si periodic if there exists integer $K &gt; 1$ s.t. all loops in its underlying graph which contain vertex $P_i$ have length divisible by $K$.</li>
<li>Markov chains which do not have any periodic states are called aperiodic</li>
</ul>
</li>
<li>For any finite, irreducible and aperiodic Markov chain has the following properties:
<ol>
<li>For every initial distribution of states $\mathbf{q}^{(0)}$ the value of $\mathbf{q}^{(t)} = \mathbf{q}^{(0)}G^t$ converges as $t \rightarrow \infty$ to a unique stationary distribution $\mathbf{q}$, i.e., converges to a unique distribution $\mathbf{q}$ which is independent of $\mathbf{q}^{(0)}$ and satisfies $\mathbf{q} = \mathbf{q}G$.</li>
<li>Note: in the above $\mathbf{q}$ is a row vector, to avoid having to always transpose it.</li>
<li>Let $N(P_i, T)$ be the number of times the system has ben in state $P_i$ during $T$ many transitions of such a Markov chain, then
$$\lim_{T \rightarrow \infty} \frac{N(P_i, T)}{T}= \mathbf{q_i}$$</li>
</ol>
</li>
</ul>
<h4 id="application-to-pagerank">Application to PageRank</h4>
<p>The general theorem on Markov chains implies that:</p>
<ul>
<li>1 is the left eigenvalue of $G$ of the largest absolute value, and the <em>stationary distribution</em> $\mathbf{q}$ is the corresponding left hand side eigenvector, $\mathbf{q}^\intercal = \mathbf{q}^\intercal G$.</li>
<li>$\mathbf{q}$ is unique, i.e., if $\mathbf{q}_1^\intercal = \mathbf{q}_1^\intercal G$, then $\mathbf{q}_1 = \mathbf{q}$</li>
<li>Distribution $\mathbf{q}$ can be obtained by starting with an arbitrary initial probability distribution $\mathbf{q}_0$ and obtain $\mathbf{q}$ as $\lim_{k \rightarrow \infty} \mathbf{q}_0^\intercal G^k$</li>
<li>An approximation $\mathbf{\tilde{q}}$ of $\mathbf{q}$ can be obtained by taking $\mathbf{q}_o^\intercal = (1/M, 1/M, &hellip;, 1/M)$ and a sufficiently large $K$ and computing $\mathbf{\tilde{q}} = \mathbf{q}_0 G^k$ iteratively</li>
<li>The $i^{th}$ coordinate of such obtained distribution $\mathbf{q}^\intercal = (q_1, &hellip;, q_i, &hellip;, q_M)$ roughly gives the ratio $N(P_i, T)/T$ where $N(P_i, T)$ is the number of times $P_i$ has been visited during a surfing session of length $T$.</li>
</ul>
<h4 id="finding-alpha">Finding alpha</h4>
<p>How close to 1 should $\alpha$ be?</p>
<p>The <em>expected</em> length $lh$ of surfing between two teleportations can be found as:</p>
<p>$$
\begin{align*}
E(lh)
&amp;= 0(1 - \alpha) + \alpha(1 - \alpha) + &hellip; + k \alpha^k (1 - \alpha) + &hellip; \\
&amp;= \alpha(1 - \alpha)(1 + 2 \alpha + &hellip; + k \alpha^{k - 1} + &hellip;) \\
&amp;= \frac{\alpha}{1 - \alpha}.
\end{align*}
$$</p>
<p>Google uses $\alpha = 0.85$ (obtained empirically), giving an expected surfing length $\frac{0.85}{1- 0.85}\approx 5.7$, very close to 6 (coming from the idea of <em>six degrees of separation</em>), and it takes approx $50 - 100$ iterations for convergence.</p>
<p>Larger values produce more accurate representation of &ldquo;importance&rdquo; of a webpage, but the convergence slows down fast.</p>
<p>Error of approximation of $\mathbf{q}$ by $\mathbf{q_0}G^k$ decreases approximately as $\alpha^k$.
More importantly, increasing $\alpha$ increases the sensitivity of the resulting PageRank.
This is not effective as internet content and structure changes on a daily basis, but PageRank should change slowly.</p>
<h2 id="hidden-markov-models-and-the-viterbi-algorithm-and-its-applications">Hidden Markov Models and the Viterbi Algorithm and its applications</h2>
<p>A Hidden Markov Model is a Markov Model that has two states:</p>
<ul>
<li>observations</li>
<li>hidden states</li>
</ul>
<p>An example of it&rsquo;s application, is given a sequence of manifestations, how can we determine what sequence of states caused it?</p>
<p>We do it in a way that maximises the likelihood that we are correct which is what the <strong>Viterbi algorithm</strong> does. It is a dynamic programming algorithm that produces the most likely estimate.</p>
<h3 id="hidden-markov-models">Hidden Markov Models</h3>
<ul>
<li>If we are given a finite Markov chain, consisting of a set of its states $S = \{s_1, s_2, &hellip;, s_K \}$.</li>
<li>We are also given the initial probabilities $\pi_1, \pi_2, &hellip;, \pi_K$ of states.</li>
<li>However, we have no access to the direct states, we only have the set of observables $O = \{o_1, o_2, &hellip;, o_N \}$ which are the possible manifestations of the states $S = \{s_1, s_2, &hellip;, s_K \}$.</li>
<li>We are also given the emission matrix $E$ of size $K \times N$ where entry $e(i, k)$ represents the probability that when the chain is in state $s_i$, the observable outcome will be $o_k$.</li>
</ul>
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<h3 id="maximum-likelihood-estimation">Maximum Likelihood Estimation</h3>
<p>Likelihood is, in a sense, an inverse of probability.</p>
<ul>
<li>Assume there are $n$ balls labeled 1 to $n$, and you can draw a single ball, look at its value, and have to estimate the value of $n$.</li>
<li>Assume you drew the ball numbered $k$, which has a probability of $1 / n$. Therefore you have the highest chance of picking $k$ when $n$ is as small as possible, meaning it $n = k$ (as you know there are at least $k$ balls).</li>
<li>In this case the MLE estimator is $N(X) = X$, and $E(X)$ is given by
$$\mu = \sum_{i=1}^{n}\left( i \times \frac{1}{n} \right) = \frac{n(n + 1)}{2n} = \frac{n + 1}{2}.$$
Thus, this is biased, because the expected value is half of $n$.</li>
<li>If we ues the estimator $Y(X) = 2X - 1$, then the expected value of $Y$ is
$$\sum_{i = 1}^{n} \frac{2i - 1}{n} = \frac{2\sum_{i=1}^{n}i}{n} - \frac{\sum_{i=1}^n 1}{n} = \frac{2n(n+1)}{2n} - 1 = n$$
and this is unbiased.</li>
<li>As the size of the sample increases, ML estimate approaches the best possible estimate.</li>
</ul>
<h3 id="viterbi-algorithm">Viterbi Algorithm</h3>
<p>Assume we are given a sequence of observable outcomes $(y_1, y_2, y_r)$.
The goal is to find the sequence $(x_1, x_2, &hellip;, x_r)$ of states of the Markov chain for which the likelihood that such a sequence is the cause of the observed sequence of outcomes is the highest.</p>
<ul>
<li>Given $\vec{y}$ observed, we could pick the sequence of states $\vec{x}$ for which the value of $P(\vec{x}, \vec{y})$ is the largest.</li>
<li>This is not feasible, as if the total number of states is $K$ and the observed sequence is of length $T$ then there are $K^T$ sequences to try.</li>
<li>Instead the Viterbi algorithm solves this problem in $O(T \times K^2)$ using dynamic programming.</li>
</ul>
<h4 id="algorithm-1">Algorithm</h4>
<p>We solve all subproblems $S(i, k)$ for every $i \leq i \leq T$ and every $1 \leq k \leq K$:</p>
<p><strong>Subproblem</strong> $S(i, k)$: Find the sequence of states $(x_1, &hellip;, x_i)$ such that $x_i = s_k$ and such that the probability of observing the outcome $(y_1, &hellip;, y_i)$ is maximal.</p>
<p>A <a href="https://www.youtube.com/watch?v=kqSzLo9fenk">good intro to Hidden Markov Models and the Viterbi Algorithm</a>.</p>
<h2 id="recommender-systems">Recommender Systems</h2>
<p>The main purpose of recommender systems is to recommend content / products to users that they may enjoy.</p>
<p>Two major kinds of recommender systems:</p>
<ul>
<li><strong>Content based:</strong> items are recommended by their intrinsic similarity
<ul>
<li>This suffers from the problem that content usually has to be done by humans because content is a semantic notion (which computers do not understand well)</li>
</ul>
</li>
<li><strong>Collaborative filtering:</strong> items are recommended based on some similarity measure between users and between items based on rating of items by the community of users
<ul>
<li>This tends to be superior in performance and does not rely on human advice</li>
<li>There are two main approaches:</li>
<li><strong>Neighbourhood Method:</strong>
<ul>
<li>Based on the similarity of users</li>
<li>If $A$ and $B$ gave similar evaluations to movies that they have both seen, if $A$ liked something $b$ has not seen, then $B$ may like it as well</li>
</ul>
</li>
<li><strong>Latent Factor Method:</strong>
<ul>
<li>Based on the similarity of items</li>
<li>Assume two movies $M_1$ and $M_2$ had similar ratings, then if someone liked $M_1$, then it is reasonable to recommend movie $M_2$ to such a user</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>We can construct a sparsely populated table of ratings $R$, the rows correspond to movies, the columns to users.
The entry $r(i, j)$ of the table, if non empty, represents teh rating user $U_i$ gave to some movie $M_j$
Each entry may have some rating in range $0 - 5$ (or a similar relatively small rating range, usually with at most 10 or so levels).</p>
<h3 id="neighbourhood-method">Neighbourhood Method</h3>
<p>We replace these rating integers with more informative numbers.</p>
<ul>
<li>First we compute the mean $\bar{r}$ of all ratings for all movies</li>
<li>Then we obtain $\bar{R}$ by subtracting $\bar{r}$ from all values</li>
<li>Now if a value $r&rsquo;(i, j) &gt; 0$ then $U_i$ liked $M_j$ above the global average ($r&rsquo;(i, j)$ can be positive or negative with equal probability).
However, some ratings may be influenced by &ldquo;hype&rdquo; or &ldquo;trendiness&rdquo; AKA  systematic biases&quot;.</li>
<li>To remove this:
<ul>
<li>For every user $U_i$, introduce $v_i$, the &ldquo;individual bias&rdquo; of user $U_i$, reflecting tendency to give overall higher or lower scores.</li>
<li>For every movie $M_j$, introduce $\mu_j$, the &ldquo;hype bias&rdquo; of movie $M_j$ which is how &ldquo;fashionable&rdquo; the movie is (which fades with time).</li>
<li>Both systematic biases can be removed by seeking the values of $v_i$ and $\mu_j$ which minimises the expression
$$S(\vec{v}, \vec{\mu}) = \sum_{(i, j) \in R}(r&rsquo;(i, j) - v_i - \mu_j)^2$$</li>
<li>Note that $\mu$&rsquo;s are constant shifts of rows (each row corresponding to a movie) and $v$&rsquo;s are constant shifts of columns (each corresponding to a user).
This is a <strong>Least squares</strong> problem, and $S(\vec{v}, \vec{\mu})$ achieves a minimum when all the partial derivatives are equal to 0:
$$
\begin{align*}
\frac{\partial}{\partial v_i}S(\vec{v}, \vec{\mu}) &amp;= -2 \sum_{j:(i, j) \in R}(r&rsquo;(j, i) - v_i - \mu_j) = 0 \\\
\frac{\partial}{\partial \mu_j}S(\vec{v}, \vec{\mu}) &amp;= -2 \sum_{i:(i, j) \in R}(r&rsquo;(j, i) - v_i - \mu_j) = 0 \\\
\end{align*}
$$</li>
<li>Unfortunately, Least Squares fits usually suffer from overfitting.
The solution for this is called <strong>regularisation</strong>: where we introduce a term which penalises for large values of the variables.
Thus instead, we minimise the sum:
$$S(\vec{v}, \vec{\mu}, \lambda) = \sum_{(i, j) \in R}(r&rsquo;(i, j) - v_i - \mu_j)^2 + \lambda \left( \sum_i v_i^2 + \sum_j \mu_j^2 \right)$$
where $\lambda$ is a suitably chosen small positive constant, usually $10^{-10} \leq \lambda \leq 10^{-2}$ (the optimal value of $\lambda$ can also be &ldquo;learned&rdquo;)</li>
<li>We now obtain from $\bar{R}$ $\tilde{R}$ and are ready to estimate similarities of users and movies</li>
</ul>
</li>
</ul>
<h4 id="neighbourhood-method---similarity-of-users">Neighbourhood Method - Similarity of users</h4>
<p>One of the most frequently used measure of similarity of users is the <strong>cosine similarity measure</strong>.</p>
<p>If we want to compare 2 users $U_i$ and $U_k$, we find all movies that both users have ranked and delete all other entries.
We obtain two column vectors $\vec{u}_1$ and $\vec{v}_k$, and the similarity of the two users is measured by the cosine of the angle between these two vectors.</p>
<p>$$
\begin{align*}
\text{sim}(U_i, U_k)
&amp;= \cos(u_i, u_k) \\
&amp;= \frac{\langle \vec{u}_i, \vec{u}_k \rangle}{|\vec{u}_i| \cdot |\vec{u}_k|}
\end{align*}
$$</p>
<p>We can now predict the rating a user $U_i$ would give to a movie $M_j$ they have not seen as follows:</p>
<ol>
<li>Among all users who have seen $M_j$, pick $L$ many users $U_{k_l}$ with $L$ largest values of $|\text{sim}(U_i, U_{k_l})|$ (i.e. the $L$ top similar and dissimilar values).</li>
<li>We now predict the rating user $U_i$ would give to movie $M_j$ as
$$\text{pred}(i, j) = \bar{r} + v_i + \mu_j + \frac{\sum_{1 \leq l \leq L} \text{sim}(U_i, U_{k_l}) \tilde{r}(j, k_l)}{\sum_{1 \leq l \leq L} |\text{sim}(U_i, U_{k_l})|}$$</li>
<li>We then recommend to user $U_i$ movie $M_j$ for which the predicted rating $\text{pred}(i, j)$ is the highest
<ul>
<li>The &ldquo;hype factor&rdquo; $\mu_j$ is brought back when deciding what to recommend).</li>
<li>$v_i$ is constant across movies, so it is insignificant; adding it is mostly for test purposes because it will realistically predict the possible rating of $U_i$ of $M_j$ allowing easy comparison in tests</li>
</ul>
</li>
</ol>
<h4 id="neighbourhood-method---similarity-of-movies">Neighbourhood Method - Similarity of movies</h4>
<p>We can in a similar way estimate similarity of movies, working on the columns of $\tilde{R}$ (instead of rows).
We predict the rating user $U_i$ would give to the move $M_j$ as</p>
<p>$$
\text{pred} =
\bar{r} + v_i + \mu_j + \frac{\sum_{1 \leq l \leq L} \text{sim}(M_j, M_{n_l}) \tilde{r}(n_l, i)}{\sum_{1 \leq l \leq L} |\text{sim}(M_j, M_{n_l})|}
$$</p>
<p>and recommend the movie $M_j$ that has the highest value of $\text{pred}(j, i)$.</p>
<h3 id="latent-factor-method">Latent Factor Method</h3>
<p>This method relies on several heuristics</p>
<ul>
<li>
<p>There are features movies posses which appeal to different tastes which determine how much a user likes a movie. I.e. &ldquo;action&rdquo;, &ldquo;comedy&rdquo;, &ldquo;romance&rdquo;, &ldquo;famous actors&rdquo;, &ldquo;special effects&rdquo;</p>
</li>
<li>
<p>Enumerate these features as $f_1, f_2, &hellip;, f_N$ where $N$ is to the order of a few 10s to a few 100s
A movie can have each of these features, say $f_i$ to an extent $e_i$, where say $0 \leq e_i \leq 10$.</p>
</li>
<li>
<p>Each movie $M_j$ has a vector $\vec{e}^j$ of length $N$, and we can form a matrix $F$ s.t. rows of $F$ correspond to movies and columns correspond to features. I.e. if we have $M$ movies:
$$
F =
\begin{pmatrix}
F_{1, 1}  &amp; \ldots &amp; F_{1, N} \\
\vdots    &amp; \vdots &amp; \vdots   \\
\vdots    &amp; \vdots &amp; \vdots   \\
\vdots    &amp; \vdots &amp; \vdots   \\
\vdots    &amp; \vdots &amp; \vdots   \\
\vdots    &amp; \vdots &amp; \vdots   \\
F_{M, 1}  &amp; \ldots &amp; F_{M, N}
\end{pmatrix}
$$
resulting in a very tall matrix</p>
</li>
<li>
<p>We can associate each user $U_i$ with a column vector $\vec{l}^i$ s.t. its $m^{th}$ coordinate is a number, $0 \leq \vec{l}^i_m \leq 10$ which represents how much a user likes a feature $f_m$ in a movie.</p>
</li>
<li>
<p>We can now form a matrix $L$ whose rows correspond to features and columns correspond to users.
$$
L =
\begin{pmatrix}
L_{1, 1}  &amp; \ldots &amp; \ldots &amp; \ldots &amp; \ldots &amp; \ldots &amp; L_{1, N} \\
\vdots    &amp; \ldots &amp; \ldots &amp; \ldots &amp; \ldots &amp; \ldots &amp; \vdots   \\
L_{M, 1}  &amp; \ldots &amp; \ldots &amp; \ldots &amp; \ldots &amp; \ldots &amp; L_{M, N}
\end{pmatrix}
$$
resulting in a very wide matrix</p>
</li>
</ul>
<p>Assume that we have access to $L$ and $F$.
Then to predict how much $U_i$ likes $M_j$, we evaluate</p>
<p>$$E(j, i) = \sum_{1 \leq m \leq N} (\vec{e}^j)_m (\vec{l}^i)_m = \langle \vec{e}^j, \vec{l}^i \rangle.$$</p>
<p>and as a result can generate $E = F \times L$, resulting in a very large matrix.
However, the issue is that we cannot determine which few dozen features are relevant out of a few hundred features.</p>
<h4 id="finding-relevant-features">Finding relevant features</h4>
<p>Let $N$ be the number of features we want (typically $20 \leq N \leq 200$), $\#M$ by the number of movies, and $\#U$ be the number of users.</p>
<p>Fill matrices $F$ of size $\#M \times N$ and $L$ of size $N \times \#U$ with variables $F(j, m)$ and $L(m, i)$ whose values have yet to be determined.</p>
<p>Then sole the least squares problem in the variables
$$\{ F(j, m): 1 \leq j \leq \#M; 1 \leq m \leq N \} \cup \{ L(m, i) : 1 \leq m \leq N; 1 \leq i \leq \#U \}$$</p>
<p>minimise</p>
<p>$$S(\vec{F}, \vec{L}) = \sum_{(j, i):R(j, i)} \left( \sum_{1 \leq m \leq N} F(j, m) \cdot L(m, i) - R(j, i) \right)^2$$</p>
<p>We can attempt to find the minimum by finding the when the partial derivative of $S(\vec{F}, \vec{L})$ is equal to 0.
However:</p>
<ul>
<li>this results in a huge system of cubic equations that cannot be solved feasibly</li>
<li>an optimisation problem is not convex, so search for the optimal solution can end up in a local minimum</li>
</ul>
<p>Solution:</p>
<ol>
<li>
<p>Set all variables $F(j, m)$ to the same value $F^{(0)}(j, m)$ as a median value</p>
</li>
<li>
<p>Now solve the following Least Squares problem for the variables
$$\{ L(m, i) : 1 \leq m \leq N; 1 \leq i \leq \#U \}$$
minimise
$$\sum_{j, i}: R(j, i) \left(\sum{1 \leq m \leq N} F^{(0)}(j, m) \cdot L(m, i) - R(j, i) \right)^2$$
which is now a system of linear equations as after we find the partials $F^{(0)}(j, m)$ is set to 0.</p>
</li>
<li>
<p>Let $L^{(0)}(m, i)$ be the solutions to such a Least Squares problem.</p>
</li>
<li>
<p>We now solve the following Least Squares problem in variables
$$\{ F(j, m): 1 \leq j \leq \#M; 1 \leq m \leq N \}$$
minimise
$$\sum_{(j, i):R(j, i)} \left( \sum_{1 \leq m \leq N} F(j, m) \cdot L^{(0)}(m, i) - R(j, i) \right)^2$$</p>
</li>
<li>
<p>Now, we keep alternating between taking either $\{ L(m, i) : 1 \leq m \leq N; 1 \leq i \leq \#U \}$ or $\{ F(j, m): 1 \leq j \leq \#M; 1 \leq m \leq N \}$ as free variables, fixing the values of the other set from the previously obtained solution to the corresponding Least Squares problem.</p>
<p>This method is sometimes called <strong>Method of Alternating Projections</strong>.</p>
</li>
<li>
<p>We stop such iterations when
$$\sum_{(j. m)}(F^{(k)}(j. m) - F^{(k - 1)}(j. m))^2 + \sum_{(i. m)}(L^{(k)}(m, i) - L^{(k - 1)}(m, i))^2$$
becomes smaller than an accuracy threshold $\epsilon &gt; 0$.</p>
</li>
<li>
<p>After we obtain the values $F^{(k)}(j, m)$ and $L^{(k)}(m, i)$ from the last iteration $k$, we form teh corresponding matrices $F$ of size $\#M \times N$ and $L$ of size $N \times \#U$ as
$$
\begin{align*}
\tilde{F} &amp;= \left( F^{(k)}(j, m) : 1 \leq j \leq \#M; 1 \leq m \leq N \right) \\
\tilde{L} &amp;= \left( L^{(k)}(m, i) : 1 \leq m \leq \#M; 1 \leq m \leq \#U \right) \\
\end{align*}
$$</p>
</li>
<li>
<p>We finally set $E = \tilde{F} \times \tilde{L}$ as the final matrix of predicted ratings of all movies by all users, where $E(j, i)$ is the prediction of the rating of movie $M_j$ by user $U_i$.</p>
</li>
</ol>
<ul>
<li>Note we do not know what these latent features actually are</li>
<li>However, the Latent Factor Method performs remarkably well in many domains</li>
<li>Though in a Netflix Challenge competition to design the best recommendation algorithm, the top algorithms were combination of dozens of components / algorithms with empirically tuned parameters</li>
</ul>
<h2 id="clustering-algorithms">Clustering Algorithms</h2>
<p>Clustering algorithms are a type of unsupervised learning used in data science.</p>
<p>There are two kinds of clusters:</p>
<ol>
<li>center - based clusters</li>
<li>high density clusters</li>
</ol>
<p>A good clustering algorithm should be able to handle both kinds.</p>
<h3 id="data-representation">Data Representation</h3>
<p>There are two common representations of points</p>
<h4 id="as-vectors-in-mathbbrd">As vectors in $\mathbb{R}^d$</h4>
<ul>
<li>This is suitable when you have several numerical measurements (and each measurement maps to a dimension).</li>
<li>Note $d$ can be extremely large, corresponding to thousands or more, and can be complex to store and handle such data. This is where Johnson - Lindenstrauss Theorem comes to play.</li>
</ul>
<h4 id="as-a-weighted-graph">As a weighted graph</h4>
<ul>
<li>Data points are represented as vertices of the graph</li>
<li>The weights of the edges reflect the degree of similarity (or dissimilarity) of the data points.
The distance between two data points $x, y \in \mathbb{R}^d$ can be defined as either
$$d(x, y) = \sum_{i=1}^d |x_i - y_i| \quad \text{or} \quad d(x, y) = \sqrt{\sum_{i=1}^d (x_i - y_i)^2}$$</li>
<li>If the scales of the $i^{th}$ and $j^{th}$ coordinates $x_i$ and $x_j$ differ significantly, or if they are not of equal importance, we might consider instead
$$d(x, y)^2 = \sum_{i=1}^d w_i(x_i - y_i)^2$$
where the weights $w_i$ are chosen to normalise different variances of $x_i$ and $x_j$ or to encode their relative significances.</li>
<li>Graph representation of data is often much more compact than vectors, as it does not suffer from problems of high dimensionality.</li>
<li>However, the geometry of the data is lost, so the clustering is based only on mutual distances of pairs of points, which is good when clustering is not center based.</li>
</ul>
<h3 id="center-based-clustering-algorithms">Center-based Clustering Algorithms</h3>
<p>We assume data points are represented as vectors in $\mathbb{R}^d$.</p>
<h4 id="k-center-clustering">k-center clustering</h4>
<p>Find a partition $C = \{C_1, &hellip;, C_k \}$ of a set of data points $A = \{\mathbf{a_1}, &hellip;, \mathbf{a_n} \}$ into $k$ clusters, with the corresponding centers $\mathbf{c_1}, &hellip;, \mathbf{c_k}$ which minimises</p>
<p>$$\Phi(C) = \max_{j=1}^k \max_{a \in C_j} d(\mathbf{a}, \mathbf{c_j})$$</p>
<p>This will minimise the radius of the cluster (as the radius of a cluster is the furthest distance from the cluster center).</p>
<h4 id="k-median-clustering">k-median clustering</h4>
<p>Find a partition $C = \{C_1, &hellip;, C_k \}$ of a set of data points $A = \{\mathbf{a_1}, &hellip;, \mathbf{a_n} \}$ into $k$ clusters, with the corresponding centers $\mathbf{c_1}, &hellip;, \mathbf{c_k}$ which minimises</p>
<p>$$\Phi(C) = \sum_{j=1}^k \sum_{a \in C_j} d(\mathbf{a}, \mathbf{c_j})$$</p>
<p>$d(\mathbf{a}, \mathbf{c}_j)$ can be any distance metric, such as</p>
<ul>
<li>$l_1$: $d(\mathbf{a}, \mathbf{c}<em>j) = \sum</em>{k=1}^d| (\mathbf{a})_k - (\mathbf{c}_j)_k |$</li>
<li>$l_2$: $d(\mathbf{a}, \mathbf{c}<em>j) = \sqrt{\sum</em>{k=1}^d ((\mathbf{a})_k - (\mathbf{c}_j)_k)^2}$
If the distance is the $l_1$ distance, one can show that the coordinates of the optimal centers are the coordinate-wise medians of points in each cluster.</li>
</ul>
<h4 id="k-means-clustering">k-means clustering</h4>
<p>This is the most frequently used center based clustering algorithm.
It is similar to the k-median clustering, except we want to minimise</p>
<p>$$\Phi(C) = \sum_{j=1}^k \sum_{a \in C_j} d(\mathbf{a}, \mathbf{c_j})^2$$</p>
<ul>
<li>This penalises more for larger distances than the k-median clustering</li>
<li>This has other nice properties; for example, if $d(\mathbf{a}, \mathbf{c_j})^2 = \sum_{j=1}^d (a_i - c_{ji})^2$  then $\mathbf{c_j}$ must be the centroids of the points in their cluster.</li>
</ul>
<h4 id="definitions">Definitions</h4>
<p><strong>Finding the centroid</strong></p>
<p>Since</p>
<p>$$\mathbf{a_i} = (a_{i1}, &hellip;, a_{id})$$</p>
<p>let $\mathbf{c} = (c_1, &hellip;, c_d)$ with for all $1 \leq k \leq d$,</p>
<p>$$c_k = (a_{1k} + &hellip; + a_{nk}) / n$$</p>
<p>As a result, $c_k$ is the arithmetic mean of the $k^{th}$ coordinates of all the points $\{ \mathbf{a}_1, &hellip;, \mathbf{a}_n \}$.
Hence, $\mathbf{c}$ is called the centroid of the set of points $\{ \mathbf{a}_1, &hellip;, \mathbf{a}_n \}$.</p>
<p><strong>Finding the distance</strong></p>
<p>Then $\mathbf{c}$ is called the centroid of the set of points $\{ \mathbf{a_1}, &hellip;, \mathbf{a_n} \}$.</p>
<p>We denote $\mathbf{x} \cdot \mathbf{y}$ the scalar product of vectors $\mathbf{x}$ and $\mathbf{y}$ by $|| \mathbf{x} ||$ the norm of a vector $\mathbf{x}$, i.e.</p>
<p>$$\mathbf{x} \cdot \mathbf{y} = \sum_{i=1}^d x_i y_i \quad \text{and} \quad ||x|| = \sqrt{\sum{i=1}^d x_i^2} = \sqrt{\mathbf{x} \cdot \mathbf{x}}$$</p>
<p>Note that $|| \mathbf{x} - \mathbf{y} ||$ is the Euclidean distance of points $\mathbf{x}$ and $\mathbf{y}$:</p>
<p>$$|| \mathbf{x} - \mathbf{y} || = \sqrt{\sum_{i=1}^d(x_i - y_i)^2}$$</p>
<p><strong>Theorem</strong></p>
<p>Let $A = \{\mathbf{a_1}, &hellip;, \mathbf{a_n} \}$ be a set of points and $\mathbf{x}$ be another point, all in $\mathbb{R}^d$. Let also $\mathbf{c}$ be the centroid of $A$.
Then</p>
<p>$$\sum_{i=1}^n || \mathbf{a_i} - \mathbf{x} ||^2 + n||\mathbf{c} - \mathbf{x}||^2$$</p>
<p><strong>Corollary</strong></p>
<p>Let $A = \{\mathbf{a_1}, &hellip;, \mathbf{a_n} \}$ be a set of points and $\mathbf{x}$ be another point, all in $\mathbb{R}^d$.
Then</p>
<p>$$D(x) = \sum_{i=1}^n || \mathbf{a_i} - \mathbf{x} ||^2$$</p>
<p>is minimised when $\mathbf{x}$ is the centroid $\mathbf{c} = \frac{1}{n} \sum_{i=1}^n \mathbf{x_i}$.</p>
<h4 id="implementation">Implementation</h4>
<p>Thus, to find a partition of set of points $A$ into $k$ disjoint components $A = \bigcup_{i=1}^k A_i$ and $k$ points $\mathbf{x_1}, &hellip;, \mathbf{x_k}$ such that the sum</p>
<p>$$\sum{j=1}^k \sum{\mathbf{a_i} \in A_j} || \mathbf{a_i} - \mathbf{x_j} ||^2$$</p>
<p>is as small as possible, then whatever such an optimal partition $\{ A_j : 1 \leq j \leq k \}$ might be, the points $\mathbf{x_j}$ must be the centroids $\mathbf{c_j}$ of sets $A_j$.</p>
<p>Hence, finding the $k$ clusters is equivalent to minimising</p>
<p>$$\sum_{m=1}^k \frac{1}{2|A_m|} \sum_{\mathbf{a_i}, \mathbf{a_j} \in A_m} || \mathbf{a_i} - \mathbf{a_j} ||^2$$</p>
<h4 id="lloyds-algorithm">Lloyd&rsquo;s Algorithm</h4>
<p>Solving the optimal k-means clustering is NP hard, so we use approximate algorithms.</p>
<p>The best known approximate k-means clustering algorithm is Lloyd&rsquo;s algorithm.</p>
<ol>
<li>Start with an initial set of cluster centers $\{\mathbf{c}^{(0)}_m : 1 \leq m \leq k\}$</li>
<li>Cluster all points $\mathbf{a} \in A$ into clusters $A_m$ by associating each $\mathbf{a} \in A$ with the nearest cluster centre.</li>
<li>Replace cluster centres with the centroids of thus obtained clusters.</li>
<li>Repeat 2 and 3 until cluster centers (and thus also clusters) stop changing.</li>
</ol>
<p>At every round $p$ of its loop, Lloyd&rsquo;s algorithm reduces the size of</p>
<p>$$\sum_{m=1}^k \sum_{\mathbf{a}_j \in A_m^{(p)}} || \mathbf{a}_j - \mathbf{c}_m^{(p)} ||^2$$</p>
<p>where $A_m^{(p)}$ are the &ldquo;temporary&rdquo; clusters and $\mathbf{c}^{(p)}_m$ is the &ldquo;temporary&rdquo; centre of cluster $A_m^{(p)}$ at round $p$ of the loop.</p>
<p>However, the algorithm may stop at a local minimum and not the global minimum.</p>
<ul>
<li>We may choose to run this algorithm multiple times and return the best result</li>
<li>Another algorithm called the <strong>Farthest Traversal k-clustering</strong> picks a random point $a_q$ from $A$ as the first center, and then pick the furthest point in $A$ from $a_q$ as the second point, and continue picking the next center as the one with the largest minimum distance from the already picked centers
<ul>
<li>If $A$ has a clustering radius of $r$, then this algorithm produces a radius at most $2r$.</li>
</ul>
</li>
<li>We can randomise the selection by picking a point with probability proportional to the shortest distance to one of already picked points</li>
</ul>
<h4 id="wards-algorithm">Ward&rsquo;s Algorithm</h4>
<p>Wards algorithm is a greedy k-means algorithm:</p>
<ol>
<li>
<p>Start with every point $\mathbf{a}_i$ in its own cluster.</p>
</li>
<li>
<p>While the number of clusters is larger than $k$ repeat:</p>
<p>Find two clusters $C$ and $C&rsquo;$ such that
$$\text{cost}(C \cup C&rsquo;) - \text{cost}(C) - \text{cost}(C&rsquo;)$$
is as small as possible and replace them with a single merged cluster $C \cup C&rsquo;$ with its centroid as its centre</p>
</li>
</ol>
<h3 id="center-based-clustering-algorithms-1">Center-based Clustering Algorithms</h3>
<p>There are several ways to find non centre based clusters.</p>
<h4 id="similarity-graphs">Similarity Graphs</h4>
<p>Rather than representing a set of data points $A$ with their locations, we represent them as an undirected weighted graph $G = (V, E)$.</p>
<ul>
<li>The weight $w_{ij}$ of an edge $e = (v_i, v_j)$ is equal to a similarity measure of the data points.
<ul>
<li>If $w_{ij} = 0$ then the vertices $v_i$ and $v_j$ are completely dissimilar points, and so we do not include this edge</li>
<li>Else the weight can depend on a decreasing function of the Euclidean distance, i.e.
$$e^{-\frac{|| \mathbf{a}_i - \mathbf{a}_j ||^2}{2}}$$</li>
</ul>
</li>
<li>Since the graph is weighted, the degree $d_i$ of a vertex $v_i$ is defined as
$$d_i = \sum_{j=1}^n w_{ij}$$
This degree matrix $D$ is a diagonal matrix with degree $d_i$ of vertex $v_i$ on the $i^{th}$ entry of the diagonal of $D$ and zeroes everywhere else</li>
</ul>
<p>From here there are several ways to cluster the points</p>
<ol>
<li><strong>The $\epsilon$-neighbourhood graph</strong>
<ul>
<li>We connect all pairs of vertices $v_i$, $v_j$ such that the distances between the data points $&lt; \epsilon$.</li>
<li>This distance is usually the Euclidean distance</li>
</ul>
</li>
<li><strong>The $k$-nearest neighbour graphs</strong>
<ul>
<li>There are two flavours of this
<ol>
<li><strong>Unidirectional k-nearest neighbour graph</strong>
Connect $v_i$ with $v_j$ if either $v_j$ is among $k$ nearest neightours of $v_i$ <strong>or</strong> vice versa</li>
<li><strong>Mutual k-nearest neighbour graph</strong>
Connect $v_i$ with $v_j$ if both $v_j$ is among $k$ nearest neighbours of $v_i$ <strong>and</strong> vice versa</li>
</ol>
</li>
<li>In both cases, the edge is then weighted with the degree of similarity of the vertices $v_i$ and $v_j$</li>
</ul>
</li>
<li><strong>The fully connected graphs</strong>
<ul>
<li>Connect all pairs of vertices $v_i$ and $v_j$ where the corresponding data points have a strictly positive similarity or similarity higher than some threshold $\epsilon$.</li>
<li>Often we take weights with the formula
$$w_{ij} = e^{-\frac{|| \mathbf{a}_i - \mathbf{a}_j ||^2 }{2 \theta^2}}$$</li>
<li>Here $\theta$ is a parameter which determines &ldquo;the size&rdquo; of the neighbourhood, namely how fast the similarity decreases as distance increases</li>
</ul>
</li>
</ol>
<ul>
<li>However, there is no simple way to choose a similarity graph, the best way is to try and determine one empirically</li>
</ul>
<h4 id="spectral-graph-theory">Spectral Graph Theory</h4>
<p>Recall that the $n \times n$ diagonal matrix $D$ has the degrees $d_i$ of vertices $v_i$ on its diagonal, where $d_i = \sum_{j=1}^n w_{ij}$.</p>
<p>The (unnormalised) graph Laplacian matrix $L$ is defined as</p>
<p>$$L = D - W$$</p>
<p>where $W = (w_{ij})^n_{i, j = 1}$.</p>
<p>Clearly $L$ is symmetric and does not depend on $w_{ii}$, $1 \leq i \leq n$.
Graph Laplacians are crucial for spectral clustering.</p>
<p>A matrix $M$ of size $n \times n$ is positive semi-definite if for all vectors $f \in \mathbb{R}^n$ we have</p>
<p>$$f^\intercal M f \geq 0$$</p>
<p>A symmetric matrix is positive semi-definite iff all of its eigvenvalues are real and non-negative.</p>
<p>The matrix $L = D - W$ has the following properties:</p>
<ol>
<li>For every vector $f \in \mathbb{R}^n$,
$$
\begin{align*}
f^\intercal L f
&amp;= f^\intercal D f - f^\intercal W f \\
&amp;= \sum_{i=1}^n d_i f_i^2 - \sum_{ij=1}^n w_{ij} f_i f_j \\
&amp;= \frac{1}{2} \sum_{i, j = 1}^{n} w_{ij} (f_i - f_j)^2
\end{align*}
$$</li>
<li>$L$ is a symmetric positive semi-definite matrix
As shown from (1), since $w_{ij} \geq 0$, L satifies $f^\intercal L f \geq 0$ for all vectors $f$ and is thus positive semi-definite.</li>
<li>The smallest eigenvalue of $L$ is 0 and its corresponding eigenvector is $\mathbb{1} = (1, 1, &hellip;, 1)$</li>
</ol>
<p>(Missing some Spectral Graph Theory)</p>
<p><strong>Spectral Clustering Algorithm:</strong></p>
<ol>
<li>Construct a similarity graph $G$ by one of the way described and let $W$ be its weighted adjacency matrix</li>
<li>Compute the Laplacian $L = D - W$.</li>
<li>Compute the $k$ eigenvectors $\mathbf{e}_1, &hellip;, \mathbf{e}_k$ of $L$ which correspond to $k$ smallest eigenvalues.</li>
<li>Let $E$ be the matrix of size $n \times k$ containing the eigenvectors $\mathbf{e}_1, &hellip;, \mathbf{e}_k$ as columns.</li>
<li>For $i = 1, &hellip;, n$, let $\mathbf{y}_i$ be the vector corresponding to teh $i^{th}$ row of E</li>
<li>Cluster points $\{ \mathbf{y}_1, &hellip;, \mathbf{y}_n \}$ using the k-means algorithm into clusters $C_1, &hellip;, C_k$.</li>
</ol>
<p>(Missing application of Spectral Clustering as graph partioning)</p>
<h2 id="dft-dct-convolution">DFT, DCT, Convolution</h2>
<h3 id="dft">DFT</h3>
<p>FFT is an $O(n \log n)$ DFT conversion and the IFFT can compute the IDFT in the same runtime.
The benefit of finding the DFT or IDFT of something is that it can represent data, in another form which can be more easily manipulated or used.</p>
<p>(Missing a ton of theory)</p>
<h3 id="convolution">Convolution</h3>
<p>Let $A = \langle A_0, A_1, &hellip;, A_{n-1} \rangle$ and $B = \langle B_0, B_1, &hellip;, B_{m-1} \rangle$ be two sequences of real or complex numbers.
We can now form two associated polynomials $P_A(x)$ and $P_B(x)$ with coefficients given by sequences $A$ and $B$.
Finding the multiple of these polynomials $P_C(x) = P_A(x) \cdot P_B(x)$ can be done in $O(m \times n)$.
From here, we can get the sequence of it&rsquo;s corresponding coefficients.
This sequence of length $m + n - 1$ is the linear convolution of sequences $A$ and $B$.
However, using the FFT algorithm, we can find the linear convolution of these two sequences in time $O((m + n) \log_2(m + n))$.</p>
<p>An example application is application of Gaussian smoothing to a noisy signal.</p>
<h2 id="svd">SVD</h2>
<p>Singular Value Decomposition is a way of representing a very large matrix $A$ as</p>
<p>$$A = \sum_{i=1}^r = \sigma_i u_i v_i^\intercal = UDV^\intercal$$</p>
<p>(Insert some more theory)</p>
<p><strong>To find $\mathbf{v}_1$ and $\mathbf{u}_1$:</strong></p>
<ol>
<li>Start with a random vector $\mathbf{x}$ and normalise it so that $| \mathbf{x}| = 1$.</li>
<li>Compute $\mathbf{z}_1 = A\mathbf{x}$; compute $\mathbf{z}_2 = A^\intercal z_1$; let $\rho = |\mathbf{z}_2|/|\mathbf{x}|$ and $\mathbf{x} = \mathbf{z}_2$</li>
<li>Repeat (2) until the difference between $\rho$&rsquo;s obtained in two consecutive iterations is smaller than a small threshold $\epsilon$.</li>
<li>Set $\mathbf{v}_1 = \mathbf{z}_2 / |\mathbf{z}_2|$</li>
<li>Finally, let $\sigma_1 = |A\mathbf{v}_1|$ and $\mathbf{u}_1 = A \mathbf{v}_1 / \sigma_1$</li>
</ol>
<p>This method is called the <strong>Power Method</strong> and it is fast if $A$ and thus also $A^\intercal$ are sparse.</p>
<p>A good <a href="https://www.youtube.com/watch?v=gXbThCXjZFM">series on SVD</a>.</p>
<h2 id="power-transmission-in-cellular-networks">Power Transmission in Cellular Networks</h2>
<p>The signal to interference ratio $SIR_i$ at receiver $R_i$ is given by</p>
<p>$$SIR_i = \frac{G_{ii}p_i}{\sum_{j: j \neq i}G_{ii}p_j + \eta_i}$$</p>
<p>where $\eta_i$ is the noise received by the receiver $i$ coming from the environment.
$SIR_i$ determines the capacity of the channel $C_{ii}$.
Each pair of transmitter $T_i$ and a receiver $R_i$ needs at least some channel capacity to carray information.
To achieve this, it needs $SIR_i \geq \gamma_i$.</p>
<p>We will see later how $\gamma_i$ is determined in practice.
However, we are interested in:</p>
<p>$$\text{minimise } \sum_{j=1}^n p_j$$</p>
<p>$$\text{subject to constraints } \frac{G_{ii} p_i}{\sum_{j: j \neq i}G_{ij} + \eta_i} \geq \gamma_i, \quad 1 \leq i \leq n$$</p>
<h3 id="matrix-form">Matrix Form</h3>
<p>Following this, we can simplify our original LP problem into</p>
<p>$$\text{minimise } \sum_{j=1}^n p_j$$</p>
<p>$$\text{subject to constraints } p_i - \gamma_i \sum{j:j \neq i} \frac{G_{ij}}{G_{ii}} p_j \geq \frac{\gamma_i \eta_i}{G_{ii}} \\ 1 \leq i, j \leq n, p_j &gt; 0$$</p>
<p>We can then convert this into a matrix format:</p>
<p>$$\text{minimise } \mathbf{1}^\intercal \mathbf{p}$$</p>
<p>$$\text{subject to constraints } (I - DF)\mathbf{p} \geq \mathbf{v}, \mathbf{p} \leq 0$$</p>
<p>This will have a feasible solution if we are not demanding excessively large $\gamma_i&rsquo;s$.</p>
<p>This is the case when the spectral radius (largest absolute value of the eigenvalues) of matrix $DF$ $\rho(DF)$, satisfies $\rho(DF) &lt; 1$.</p>
<p>Proof:</p>
<ul>
<li>If $A$ is square matrix and if $\rho(A) &lt; 1$ then $A^m \rightarrow 0$.</li>
<li>This is easy to see if $A$ has $n$ linearly independent eigenvectors, because in this case $A$ can be represented as
$$A = Q \Lambda Q^{-1}$$</li>
<li>Here the $i^{th}$ column of $Q$ is the eigenvector corresponding to eigenvalue $\lambda_i$
$\Lambda$ is a diagonal matrix with $\lambda_i$ in the $i^{th}$ column and row and zeroes elsewhere.
In such a case
$$A^k = Q \Lambda Q^{-1} Q \Lambda Q^{-1} &hellip; Q \Lambda Q^{-1} Q \Lambda Q^{-1} = Q \Lambda^k Q^{-1}$$</li>
<li>Since $\Lambda^k$ has $\lambda_i^k$ on the diagonal, if $\rho(A) &lt; 1$ then clearly $A^k \rightarrow 0$</li>
</ul>
<p>Moreover it is easy to see that</p>
<p>$$(I - A) \sum_{i=0}^k A^i = \sum_{i=0}^k A^i - \sum_{i=1}^{k+1}A^i = I - A^{k+1}$$</p>
<p>Thus,</p>
<p>$$\lim_{k \rightarrow \infty} \left( (I - A) \sum_{i=0}^k A^k \right) \lim_{k \rightarrow \infty}(I - A^{k + 1}),$$</p>
<p>which implies</p>
<p>$$(I - A) \sum_{i=0}^\infty A^i = I.$$</p>
<p>This shows that matrix $I - A$ is invertible and that</p>
<p>$$(I - A)^{-1} = \sum_{i=0}^\infty A^i$$</p>
<p>Applying this to matrix $A = DF$, let $\mathbf{p}^*$ be give by</p>
<p>$$\mathbf{p^*} = (I - DF)^{-1} \mathbf{v} = \sum_{i=0}^\infty (DF)^i \mathbf{v}$$</p>
<p>Then $(I - DF) \mathbf{p^*} = \mathbf{v}$ and the constraint becomes</p>
<p>$$(I - DF) \mathbf{p} \geq (I - DF) \mathbf{p^*}$$</p>
<p>i.e.</p>
<p>$$(I - DF)(\mathbf{p} - \mathbf{p^*}) \geq 0$$</p>
]]></content></item><item><title>UNSW Course Review</title><link>https://zes1092.github.io/posts/unsw-course-review/</link><pubDate>Tue, 22 Mar 2022 00:00:00 +0000</pubDate><guid>https://zes1092.github.io/posts/unsw-course-review/</guid><description>Context Before UNSW, I had major interest in mathematics pursuing actuarial studies. However, the lifestyle of an actuary seemed stagnant, so I picked a double degree in Computer Science / Mathematics as the degree was 4 years rather than studying 3 year bachelors + 5 years studying the actuarial exams, despite having 0 programming experience.</description><content type="html"><![CDATA[<h1 id="context">Context</h1>
<p>Before UNSW, I had major interest in mathematics pursuing actuarial studies.
However, the lifestyle of an actuary seemed stagnant, so I picked a double degree in Computer Science / Mathematics as the degree was 4 years rather than studying 3 year bachelors + 5 years studying the actuarial exams, despite having 0 programming experience.</p>
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
]]></content></item><item><title>COMP3821</title><link>https://zes1092.github.io/posts/comp3821/</link><pubDate>Mon, 21 Mar 2022 00:00:00 +0000</pubDate><guid>https://zes1092.github.io/posts/comp3821/</guid><description>The course is split into four topics
Divide and Conquer Greedy Algorithms Dynamic Programming Linear Programming and Reductions However for the sake of organising notes, I&amp;rsquo;ve included an extra section to cover knowledge not covered in the course&amp;rsquo;s prerequisite (COMP2521), and split Linear Programming and Reductions into two sections.
Misc Knowledge Asymptotic Runtime $O(n)$, Big O Denotes the upper bound of the runtime of an algorithm If $f(n) = O(g(n))$, there exist positive constants $c$ and $n_0$ such that $0 \leq f(n) \leq cg(n), \forall n \geq n_0$ $f(n) = O(g(n))$ means that $f(n)$ does not grow substantially faster than $g(n)$ because a multiple of $g(n)$ eventually dominates $f(n)$ Most commonly used as we are concerned with the worst runtime $\Theta(n)$, Big Theta Denotes a tight bound of the runtime of an algorithm $f(n) = \Theta(g(n))$ iff $f(n) = O(g(n))$ and $f(n) = \Omega(g(n))$ Less commonly used than $O(n)$, but more common than $\Omega(n)$ $\Omega(n)$, Big Omega Denotes the lower bound of the runtime of an algorithm If $f(n) = \Omega(g(n))$, there exist positive constants $c$ and $n_0$ such that $0 \leq cg(n) \leq f(n), \forall n \geq n_0$ $f(n) = \Omega(g(n))$ means that $f(n)$ grows at least as fast as $g(n)$, because $f(n)$ eventually dominates a multiple of $g(n)$ Least often used as we usually aren&amp;rsquo;t concerned with the best runtime Math Log Identity If $a, b, c &amp;gt; 0$ then $$a^{\log_{b}c} = c^{\log_{b}a}$$ Proof</description><content type="html"><![CDATA[<p>The course is split into four topics</p>
<ol>
<li>Divide and Conquer</li>
<li>Greedy Algorithms</li>
<li>Dynamic Programming</li>
<li>Linear Programming and Reductions</li>
</ol>
<p>However for the sake of organising notes, I&rsquo;ve included an extra section to cover knowledge not covered in the course&rsquo;s prerequisite (COMP2521), and split Linear Programming and Reductions into two sections.</p>
<h1 id="misc-knowledge">Misc Knowledge</h1>
<hr>
<h2 id="asymptotic-runtime">Asymptotic Runtime</h2>
<h3 id="on-big-o">$O(n)$, Big O</h3>
<ul>
<li>Denotes the upper bound of the runtime of an algorithm</li>
<li>If $f(n) = O(g(n))$, there exist positive constants $c$ and $n_0$ such that $0 \leq f(n) \leq cg(n),  \forall n \geq n_0$</li>
<li>$f(n) = O(g(n))$ means that $f(n)$ does not grow substantially faster than $g(n)$ because a multiple of $g(n)$ eventually dominates $f(n)$</li>
<li>Most commonly used as we are concerned with the worst runtime</li>
</ul>
<h3 id="thetan-big-theta">$\Theta(n)$, Big Theta</h3>
<ul>
<li>Denotes a tight bound of the runtime of an algorithm</li>
<li>$f(n) = \Theta(g(n))$ iff $f(n) = O(g(n))$ and $f(n) = \Omega(g(n))$</li>
<li>Less commonly used than $O(n)$, but more common than $\Omega(n)$</li>
</ul>
<h3 id="omegan-big-omega">$\Omega(n)$, Big Omega</h3>
<ul>
<li>Denotes the lower bound of the runtime of an algorithm</li>
<li>If $f(n) = \Omega(g(n))$, there exist positive constants $c$ and $n_0$ such that $0 \leq cg(n) \leq f(n),  \forall n \geq n_0$</li>
<li>$f(n) = \Omega(g(n))$ means that $f(n)$ grows at least as fast as $g(n)$, because $f(n)$ eventually dominates a multiple of $g(n)$</li>
<li>Least often used as we usually aren&rsquo;t concerned with the best runtime</li>
</ul>
<h2 id="math">Math</h2>
<h3 id="log-identity">Log Identity</h3>
<p>If $a, b, c &gt; 0$ then
$$a^{\log_{b}c} = c^{\log_{b}a}$$
Proof</p>
<p>$$
\begin{align*}
\log_{b}c \cdot \log_{b}a &amp;= log_{b}a \cdot \log_{b}c \\
\log_{b}(a^{\log_{b}c}) &amp;= \log_{b}(c^{\log_{b}a}) \\
a^{log_{b}c} &amp;= c^{\log_{b}a}
\end{align*}
$$</p>
<h3 id="roots-of-unity">Roots of Unity</h3>
<h4 id="representation">Representation</h4>
<p>Complex numbers $z = a + ib$ can be represented using</p>
<ul>
<li>$modulus$ $|z| = \sqrt{a^2 + b^2}$</li>
<li>$argument$ $\arg(z)$, which is an angle taking values in $(-\pi, \pi]$</li>
</ul>
<p>and satisfying:
$$z = |z|e^{i \arg(z)} = |z|(\cos(\arg(z)) + i \sin(\arg(z))).$$</p>
<p>and</p>
<p>$$z^n = \left(|z|e^{i \arg(z)}\right)^n = |z|^ne^{in\arg(z)} = |z|^n(n\cos(\arg(z)) + i \sin(n\arg(z))).$$</p>
<h4 id="properties">Properties</h4>
<p>Roots of unity of order $n$ are complex numbers which satisfy $z^n = 1$.</p>
<ul>
<li>If $z^n = |z|^n(\cos(n \arg(z)) + i\sin(n\arg(z))) = 1$ then $|z| = 1$ and $n\arg(z)$ is a multiple of $2\pi$</li>
<li>Thus, $n\arg( z) = 2\pi k$, i.e. $arg(z) = \frac{2\pi k}{n}$</li>
<li>We denote $\omega_n = e^{i \frac{2\pi}{n}}$, such that $\omega_n$ is called a primitive root of unity order $n$</li>
<li>A root of unity $\omega$ of order $n$ is primitive if all other roots of unity of the same order can be obtained as its powers $\omega^k$.</li>
</ul>
<p>For $\omega_n = e^{i \frac{2\pi}{n}}$ and for all $k$ such that $0 \leq k \leq n - 1$,
$$ (\omega_n^k)^n = ((\omega_n)^k)^n = (\omega_n)^{nk} = ((\omega_n)^n)^k = 1^k = 1.$$</p>
<p>If $k + m \geq n$ then $k + m = n + l$ for $l = (k + m) \mod(n)$ and we have
$$\omega_n^k \omega_n^m = \omega_n^{k+m} = \omega_n^{n+l} = \omega_n^n \omega_n^l = 1 \cdot \omega_n^l = \omega_n^l \text{ where } 0 \leq l \leq n.$$</p>
<p>Therefore, the product of any two roots of unity of the same order is just another root of unity of the same order (this is not the case for addition, as the sum of two roots of unity is usually not another root of unity).</p>
<p>The Cancellation Lemma: $\omega_{kn}^{km} = \omega_n^m$, and its proof is below
$$\omega_{kn}^{km} = (\omega_{kn})^{km} = \left(e^{i \frac{2\pi}{kn}}\right)^{km} = e^{i \frac{2\pi k m}{k n}} = e^{i \frac{2\pi m}{n}} = \left(e^{i \frac{2\pi}{n}}\right)^m = \omega_n^m.$$</p>
<h1 id="divide-and-conquer">Divide and Conquer</h1>
<hr>
<p>Divide and conquer algorithms recursively break down a problem into two or more non overlapping subproblems, before merging them together to become easy to solve.</p>
<p>Common examples of Divide and Conquer algorithms include</p>
<ul>
<li>Binary Search</li>
<li>Merge Sort</li>
<li>Fast Fourier Transform</li>
</ul>
<h2 id="sample-algorithms">Sample Algorithms</h2>
<h3 id="karatsubas-fast-integer-multiplication">Karatsuba&rsquo;s Fast Integer Multiplication</h3>
<h4 id="naive-method">Naive method</h4>
<p>Given 2 &lsquo;big integers&rsquo;, i.e. a number, stored as an array, where the values at an the $i^{th}$ index is the $i^{th}$ digit of the integer, and there are $n$ digits, a sample solution would look like</p>
<pre><code class="language-py"># Naive method for big integer multiplication

def mul(A: list[int], B: list[int]) -&gt; list[int]:
    n, m = len(A), len(B)
    C = [0] * (n + m)

    # Apply multiplication
    for i in range(n):
        for j in range(m):
            C[i + j] += A[i] * B[j]

    # Add carry amount to next digit and take mod of 10
    for i in range(n + m - 1):
        C[i + 1] += C[i] // 10
        C[i] %= 10

    return C
</code></pre>
<p>and hence have a runtime of $\Theta(n^{2})$, where $n$ is the greater number of digits.</p>
<h4 id="karatsubas-method">Karatsuba&rsquo;s method</h4>
<p>Say we want to find the solution to the multiplication of
$$P(x) = a_1x + a_0,$$
$$Q(x) = b_1x + b_0,$$
a naive solution will require 4 multiplications</p>
<ol>
<li>$A = a_1 \times b_1$</li>
<li>$B = a_1 \times b_0$</li>
<li>$C = b_1 \times a_1$</li>
<li>$D = b_0 \times a_0$</li>
</ol>
<p>$$P(x)Q(x) = Ax^2 + (B + C)x + D$$
However we know that
$$(a_1x + a_0)(b_1x + b_0) = (a_1b_1 + a_1b_0 + a_0b_1 + a_0b_0) = (A + B + C + D),$$
requiring 2 additions (which can be computed easily) and 1 multiplication. Hence to find the final multiplication, we only need three multiplications</p>
<ol>
<li>$E = (A + B + C + D) = (a_1 + a_0) \times (b_1 + b_0)$</li>
<li>$A = a_1 \times b_1$</li>
<li>$D = b_0 \times a_0$</li>
</ol>
<p>Hence to find the final solution, we can do
$$P(x)Q(x) = Ax^2 + (E - A - D)x + D$$</p>
<h4 id="karatsubas-method-for-integers">Karatsuba&rsquo;s method for integers</h4>
<p>If we want to multiply $A$ with $B$, we can represent them as</p>
<p>$$
\begin{align*}
A &amp;= 10^{\frac{n}{2}}A_1 + A_0 \\
B &amp;= 10^{\frac{n}{2}}B_1 + B_0.
\end{align*}
$$</p>
<p>With this, we can apply Karatsuba&rsquo;s method, where</p>
<p>$$
\begin{align*}
x &amp;= A_1B_1 \\
z &amp;= A_0B_0 \\
y &amp;= (A_1 + A_0)(B_1 + B_0) - x - z \\
AB
&amp;= 10^{n}x + 10^{\frac{n}{2}}y + z.
\end{align*}
$$</p>
<p>At each function call, there are 3 multiplications being performed (each of which is multiplied by the same algorithm), where the input size is halved in each recursive call, and the addition runs in $O(n)$. Therefore Karatsuba&rsquo;s method has the recurrence
$$ T(n) = 3T\left(\frac{n}{2}\right) + O(n) = O(n^{\lg 3}). $$</p>
<h4 id="karatsubas-method-for-polynomials">Karatsuba&rsquo;s method for polynomials</h4>
<p>We can view this representation of integers similar to that of polynomials. Say we are given polynomials $A(x)$, $B(x)$, where
$$A(x) = a_nx^n + a_{n-1}x^{n-1} + \ldots + a_0$$
$$B(x) = b_nx^n + b_{n-1}x^{n-1} + \ldots + b_0.$$
We have $C(x) = A(x) \cdots B(x)$ of degree $2n$
$$C(x) = \sum_{j = 0}^{2n}c_jx^j = A(x)B(x) = \sum_{j=0}^{2n} \left( \sum_{i + k = j}a_ib_k \right)x^j$$
however, we want to find the coefficients of $c_j = \sum_{i+k=j}a_ib_k$ without performing $(n+1)^2$ many multiplications necessary to get all products of the form $a_ib_k$.</p>
<h3 id="fast-fourier-transform">Fast Fourier Transform</h3>
<p>A naive way to multiply two polynomials together would be to multiply each term of the first polynomial with a term of the second polynomial. The runtime of this would be $O(n^2)$, where $n$ is the degree/ number of terms of the polynomials.</p>
<p>Another method would be to convert both polynomial into it&rsquo;s point value form, multiply those points and convert it back into the polynomial form.
The fast Fourier transform (FFT) is an algorithm to calculate the Discrete Fourier transform (DFT) of a sequence, or the inverse (IDFT) in $O(n \log n)$.</p>
<h3 id="polynomial-interpolation-vandermonde-matrix">Polynomial Interpolation (Vandermonde Matrix)</h3>
<h4 id="from-coefficient-to-value-representation">From Coefficient to Value Representation</h4>
<p>A polynomial $A(x)$ of degree $n$ is uniquely determined by its values at any $n + 1$ distinct input values $x_0, x_1, \ldots, x_n$:
$$A(x) \leftrightarrow \langle(x_0, A(x_0)), (x_1, A(x_1)), \ldots, (x_n, A(x_n))\rangle$$</p>
<p>For $A(x) = a_nx^n + a_{n-1}x^{n-1} + \ldots + a_0$, these values can be obtained via a matrix multiplication:</p>
<p>$$
\begin{pmatrix}
1      &amp; x_0    &amp; x_0^2  &amp; \ldots &amp; x_0^n  \\
1      &amp; x_1    &amp; x_1^2  &amp; \ldots &amp; x_1^n  \\
\vdots &amp; \ldots &amp; \ldots &amp; \ddots &amp; \vdots \\
1      &amp; x_n    &amp; x_n^2  &amp; \ldots &amp; x_n^n  \\
\end{pmatrix}
\begin{pmatrix}
a_0 \\
a_1 \\
\vdots \\
a_n \\
\end{pmatrix} =
\begin{pmatrix}
A(x_0) \\
A(x_1) \\
\vdots \\
A(x_n) \\
\end{pmatrix}
$$</p>
<p>Such a matrix is called the Vandermonde matrix.</p>
<h4 id="from-value-to-coefficient-representation">From Value to Coefficient Representation</h4>
<p>It can be shown that if $x_i$ are all distinct, then this matrix is invertible.
Thus, if all $x_i$ are all distinct, given any values $A(x_0), A(x_1), \ldots, A(x_n)$ the coefficients $a_0, a_1, \ldots, a_n$ of the polynomial $A(x)$ are uniquely determined:</p>
<p>$$
\begin{pmatrix}
1      &amp; x_0    &amp; x_0^2  &amp; \ldots &amp; x_0^n  \\
1      &amp; x_1    &amp; x_1^2  &amp; \ldots &amp; x_1^n  \\
\vdots &amp; \ldots &amp; \ldots &amp; \ddots &amp; \vdots \\
1      &amp; x_n    &amp; x_n^2  &amp; \ldots &amp; x_n^n  \\
\end{pmatrix}^{-1}
\begin{pmatrix}
A(x_0)    \\
A(x_1)    \\
\vdots    \\
A(x_n)    \\
\end{pmatrix} =
\begin{pmatrix}
a_0    \\
a_1    \\
\vdots \\
a_n    \\
\end{pmatrix}
$$</p>
<h4 id="complexity-of-swapping-representation">Complexity of Swapping Representation</h4>
<p>If we fix the inputs $x_0, x_1, \ldots, x_n$ then commuting between a representation of a polynomial $A(x)$ via its coefficients and a representation via its values at these points is done via the following two matrix multiplications, with matrices made from constants, and thus, for fixed inputs $x_0, x_1, \ldots, x_n$, this switch between the two kinds of representations is done in linear time.</p>
<h4 id="discrete-fourier-transform">Discrete Fourier Transform</h4>
<p>For $\mathbf{a} = \langle a_0, a_1, \ldots a_{n-1} \rangle$ a sequence of $n$ real or complex numbers, we can form the corresponding polynomial $P_A(x) = \sum_{j=0}^{n-1}a_jx^j$, and evaluate it at all complex roots of unity of order n,
$$\forall \ 0 \leq k \leq n - 1, \quad P_A(\omega_n^k) = A_k = \sum_{j=0}^{n-1}a_j\omega_n^{jk}.$$</p>
<p>The DFT of a sequence $\mathbf{a}$ is a sequence $\mathbf{A}$ of the same length.</p>
<h4 id="inverse-discrete-fourier-transform">Inverse Discrete Fourier Transform</h4>
<p>The IDFT of a sequence $\mathbf{A} = \langle A_0, A_1, \ldots, A_{n-1} \rangle$ is the sequence of values $\mathbf{a} = \langle a_0, a_1, \ldots, a_{n-1} \rangle = \langle \frac{P_a(1)}{n}, \frac{P_a(\omega_n^{-1})}{n}, \frac{P_a(\omega_n^{-2})}{n}, \ldots, \frac{P_a(\omega_n^{1-n})}{n} \rangle$.</p>
<p>We can show that IDFT(DFT($\mathbf{a}$)) = $\mathbf{a}$ and DFT(IDFT($\mathbf{A}$)) = $\mathbf{A}$.</p>
<h4 id="computation-of-dft-idft">Computation of DFT/ IDFT</h4>
<p>Brute force computation of the DFT takes $\Theta(n^2)$, same for IDFT. The DFT of a sequence can be computed in $\Theta(n \lg n)$ using the FFT (as can be the IDFT).</p>
<h2 id="proofs">Proofs</h2>
<h3 id="proof-of-correctness">Proof of Correctness</h3>
<p>For Divide and Conquer proof of correctness, mathematical induction is used.</p>
<p>Say that we want to prove that an algorithm $A(n)$ is correct.</p>
<ol>
<li>Prove that the base case is correct, i.e. $A(0)$, $A(1)$ is correct (depends on your base case)</li>
<li>Prove induction step
<ol>
<li>Assume that $A(k)$ is true, where $k &lt; n$ (Inductive hypothesis)</li>
<li>Therefore, recursive calls are correct as they call $A(k)$ where $k &lt; n$, which is true by the inductive hypothesis</li>
<li>Prove that the conquer part of the algorithm is correct</li>
</ol>
</li>
<li>Hence algorithm is correct for input size $n$</li>
</ol>
<h3 id="proof-of-runtime-master-theorem">Proof of Runtime (Master Theorem)</h3>
<h4 id="representation-1">Representation</h4>
<p>The time complexity of a divide and conquer algorithm can be represented in the form
$$T(n) = aT \left( \frac{n}{b} \right) + f(n)$$
where,</p>
<ul>
<li>$T(n)$
<ul>
<li>The divide and conquer algorithm, with an input size of $n$</li>
</ul>
</li>
<li>$a \geq 1$
<ul>
<li>$a$ is the number of recursive calls per function</li>
<li>The constraint implies we make at least 1 recursive call, otherwise there would be no recursion</li>
</ul>
</li>
<li>$b &gt; 1$
<ul>
<li>$b$ is the decrease in input size per recursive call, the constraint implying that the input size must decrease in each recursive call</li>
<li>The constraint implies that the input size must decrease at each recursive call, otherwise we would loop infinitely, never reaching the base case</li>
</ul>
</li>
<li>$f(n)$
<ul>
<li>The runtime within each function call</li>
</ul>
</li>
</ul>
<h4 id="runtime-cases">Runtime cases</h4>
<p>Using this information, we can find the runtime of most DAQ algorithms through one of the 3 cases where if $\epsilon &gt; 0$ is a constant, then</p>
<ol>
<li>If $f(n) = O(n^{\log_b a - \epsilon})$, then $T(n) = \Theta(n^{log_b a})$</li>
<li>If $f(n) = \Theta(n^{\log_b a})$, then $T(n) = \Theta(n^{log_b a} \cdot \log n)$</li>
<li>If $f(n) = \Omega(n^{\log_b a + \epsilon})$, then $T(n) = \Theta(f(n))$</li>
</ol>
<h4 id="examples">Examples</h4>
<h5 id="case-1">Case 1</h5>
<p>If $f(n) = O(n^{\log_b a - \epsilon})$, then $T(n) = \Theta(n^{log_b a})$ <br>
Work per subproblem is dwarfed by number of subproblems</p>
<ul>
<li>Binary tree DFS | $T(n) = 2T \left( \frac{n}{2} \right) + c$
<ul>
<li>Proof:
<ul>
<li>$n^{log_b a} = n^{\lg 2} = n^{1} = n$</li>
<li>$f(n) = c = \Theta(1)$</li>
</ul>
</li>
<li>Therefore $T(n) = \Theta(n^{\lg 2}) = \Theta(n)$</li>
</ul>
</li>
<li>Karatsuba&rsquo;s integer multiplication | $T(n) = 3T \left( \frac{n}{2} \right) + n$
<ul>
<li>Proof
<ul>
<li>$n^{\log_2 3} = n^{\lg 3} \approx n^{1.58}$</li>
<li>$f(n) = n = \Theta(n)$</li>
</ul>
</li>
<li>Therefore $T(n) = \Theta(n^{1.58})$</li>
</ul>
</li>
</ul>
<h5 id="case-2">Case 2</h5>
<p>If $f(n) = \Theta(n^{\log_b a})$, then $T(n) = \Theta(n^{log_b a} \cdot \log n)$ <br>
Work per subproblem is comparable to number of subproblems</p>
<ul>
<li>Binary search | $T(n) = T \left( \frac{n}{2} \right) + c$
<ul>
<li>Proof:
<ul>
<li>$n^{\log_b a} = n^{\lg 1} = n^{0} = 1$</li>
<li>$f(n) = c = \Theta(1)$</li>
</ul>
</li>
<li>Therefore $T(n) = \Theta(n^{\lg 1} \cdot \Theta(1)) = \Theta(\log n)$</li>
</ul>
</li>
<li>Merge sort | $T(n) = 2T \left( \frac{n}{2} \right) + cn$
<ul>
<li>Proof:
<ul>
<li>$n^{\log_b a} = n^{\lg 2} = n^{1} = n$</li>
<li>$f(n) = cn = \Theta(n)$</li>
</ul>
</li>
<li>Therefore $T(n) = \Theta(n^{\lg 2} \cdot \Theta(n)) = \Theta(n \log n)$</li>
</ul>
</li>
</ul>
<h5 id="case-3">Case 3</h5>
<p>If $f(n) = \Omega(n^{\log_b a + \epsilon})$, then $T(n) = \Theta(f(n))$ <br>
Work per subproblem dominates number of subproblems</p>
<h1 id="greedy-algorithms">Greedy Algorithms</h1>
<hr>
<p>Greedy algorithms are often used for optimisation problems (i.e. you want to maximise or minimise some quantity according to a set of constraints) and make the optimal choice at each step to find the overall optimal way to solve the entire problem.</p>
<p>Common examples of Greedy Algorithms include</p>
<ul>
<li>Kruksal&rsquo;s algorithm/ Prim&rsquo;s algorithm</li>
<li>A* path finding algorithm</li>
<li>Huffman encoding</li>
</ul>
<h2 id="sample-algorithms-1">Sample Algorithms</h2>
<h3 id="interval-scheduling">Interval Scheduling</h3>
<p>Given a set of $n$ tasks requests with start finish times,</p>
<p>$$R = \{(s_1, f_1), (s_2, f_2), &hellip;, (s_n, f_n)\}$$</p>
<p>we want to find the maximum number of non overlapping tasks that we can complete.</p>
<p>An example of a greedy strategy that can solve this is <strong>Earliest Finish First</strong></p>
<pre><code class="language-py">def eaf(tasks: list[tuple[int, int]]) -&gt; list[tuple[int, int]]:
    # Sort by earliest finish time
    tasks.sort(key=lambda job: job[1])
    schedule = []
    prev_finish = 0

    for (start, finish) in tasks:
        # If the task doesn't conflict with the previous finish
        if start &gt; prev_finish:
            # Add it to our schedule and update the finish time
            schedule.append((start, finish))
            prev_finish = finish

    return schedule
</code></pre>
<h4 id="runtime">Runtime</h4>
<p>The runtime of this algorithm is $O(n \log n)$ as it is dominated by the time required to sort the jobs, as the following loop runs in $O(n)$ time.</p>
<h4 id="proof-of-correctness-1">Proof of Correctness</h4>
<p>First, we prove the result is correct (i.e. there are no tasks conflicting).</p>
<p>This is true as we only add a new task to the schedule if it does not conflict with previous tasks.</p>
<h4 id="proof-of-optimality">Proof of Optimality</h4>
<p>Secondly, we prove that the result is optimal (i.e. it is indeed the maximum number of non conflicting tasks we can schedule).</p>
<p>Let $O = \{o_1, &hellip;, o_k\}$ be the tasks of an optimal solution listed in increasing order of finish time, and $G = \{g_1,&hellip;, g_k \}$ by the tasks of the EFF solution.</p>
<p>Since $O$ is optimal, it must contain at least as many tasks as $G$, hence there must be the first index $j$, where these two schedules differ, such that</p>
<p>$$
\begin{aligned}
O &amp;= \{o_1, &hellip;, o_{j - 1}, o_j, &hellip; \} \\
G &amp;= \{o_1, &hellip;, o_{j - 1}, g_j, &hellip; \}.
\end{aligned}
$$</p>
<p>Since EFF is correct and selects the earliest finish activity time, $g_j$ does not conflict with any earlier activity, and it finishes no later than $o_j$.</p>
<p>Now consider a &ldquo;greedier&rdquo; optimal solution $O&rsquo;$ where we replace $o_j$ with $g_j$ in $O$, such that</p>
<p>$$O&rsquo; = \{ o_1, &hellip;, o_{j - 1}, g_j, o_{j + 1}, &hellip; \}.$$</p>
<p>Clearly, $O&rsquo;$ is correct since $g_j$ finishes no later than $x_j$ so therefore there are no conflicts. Therefore, this new schedule has the same number of activities as $O$, and so it is at least as good.</p>
<p>By repeating this process, we will eventually convert $O$ into $G$, without decreasing the number of tasks. Therefore $G$ is optimal.</p>
<h3 id="minimum-spanning-tree-mst">Minimum Spanning Tree (MST)</h3>
<p>Let $G = (V, E)$ be a connected undirected graph.</p>
<p>A Spanning Tree is a subgraph $T = (V, E_T)$ of $G$ such that</p>
<ul>
<li>T does not contain any cycles</li>
<li>T is connected</li>
</ul>
<p>If $G$ is an edge weighted graph, then a MST is a spanning tree of minimum weight.</p>
<h4 id="kruskals-algorithm">Kruskal&rsquo;s Algorithm</h4>
<ol>
<li>Order the edges $E$ in a non-decreasing order by their weight</li>
<li>Build a tree by adding the lowest weight edge each time</li>
<li>An edge $E_i$ is added at a round $i$ of construction if it does not introduce a cycle</li>
<li>If adding an edge would introduce a cycle, that edge is discarded</li>
<li>This continues until the list of all edges has been exhausted</li>
</ol>
<h5 id="proof-of-correctness-2">Proof of Correctness</h5>
<p>Let $T$ be the output of the algorithm</p>
<ul>
<li>$T$ does not contain any cycle</li>
</ul>
<p>We show by contradiction that $T$ is connected:</p>
<ul>
<li>Assume there are two or more connected components $C_1$ and $C_2$</li>
<li>$G$ is connected, so there are some edges connecting $C_1$ to $C_2$ in $G$</li>
<li>The first of such edges would have been added to $T$ because it would not create any cycle in $T$.</li>
</ul>
<p>Therefore $T$ is a spanning tree</p>
<h5 id="proof-of-optimality-1">Proof of Optimality</h5>
<p>We consider the case where all weights are distinct.</p>
<p>Let $T$ be the output of Kruskal&rsquo;s algorithm.</p>
<ul>
<li>Consider a spanning tree $T&rsquo;$ distinct from $T$.</li>
<li>Let $e = \{u, v \}$ be the smallest-weight edge in $T$ that is not in $T&rsquo;$.</li>
<li>$T&rsquo;$ is spanning so there exists a path $P$ from $u$ to $v$.</li>
<li>Let $T&rsquo;&rsquo; = (V, \{e\} \cup E_{T&rsquo;} \backslash \{f\})$, which is spanning tree.</li>
<li>$w(e) &lt; w(f)$ because otherwise Kruskal&rsquo;s algorithm would have added $f$ to $T$ instead of $e$.</li>
<li>Furthermore, $T&rsquo;&rsquo;$ weighs less than $T&rsquo;$, so $T&rsquo;$ is not an MST.</li>
</ul>
<p>$G$ has an MST and any $T&rsquo; \neq T$ is not an MST, so $T$ is an MST.</p>
<h4 id="kruskals-vs-prims-algorithm">Kruskal&rsquo;s vs Prim&rsquo;s algorithm</h4>
<p>Prim&rsquo;s algorithm is another greedy algorithm to find the MST of a graph, however it&rsquo;s differences are listed as below.</p>
<table>
<thead>
<tr>
<th>Kruskal&rsquo;s algorithm</th>
<th>Prim&rsquo;s algorithm</th>
</tr>
</thead>
<tbody>
<tr>
<td>Tree built always remains connected</td>
<td>Tree build usually remains disconnected</td>
</tr>
<tr>
<td>Adds next cheapest edge</td>
<td>Adds next cheapest vertex</td>
</tr>
<tr>
<td>Faster for sparse graphs</td>
<td>Faster for dense graphs</td>
</tr>
</tbody>
</table>
<h2 id="proofs-1">Proofs</h2>
<p>Whilst greedy algorithms typically have a structure for correctness and optimality, the proof of runtime varies a lot depending on the data structures and algorithms used.</p>
<h3 id="proof-of-correctness-and-optimality">Proof of Correctness and Optimality</h3>
<p>Note that greedy algorithms are typically used to maximise or minimise a quantity under a constraint.</p>
<p>We typically prove for correctness - that it satisfies the constraints of the problem (i.e. in task scheduling, we prove no two tasks overlap).</p>
<p>Secondly prove that the greedy method is achieves the most optimal solution (i.e. it does maximise or minimises a quantity). This can be done multiple ways</p>
<ol>
<li>
<p><strong>Greedy stays ahead</strong>: This works by showing that according to the measure of optimality, the greedy algorithm is at least as far ahead as the optimal solution during each iteration of the algorithm. It is typically done in 4 steps.</p>
<ol>
<li><strong>Define your solution</strong> Introduce variables to denote the greedy solution $G$ and the optimal solution $O$ (i.e. for task scheduling, it is the set of tasks).</li>
<li><strong>Define your measure</strong> Define a measure of optimality (i.e. for tasks scheduling, it is the number of jobs).</li>
<li><strong>Prove greedy stays ahead</strong> Prove that the measure of optimality for the greedy solution is at least as good as the optimal.</li>
<li><strong>Prove optimality</strong> Because the greedy solution stays ahead, it must produce an optimal solution. This is typically done by contradiction by assuming the greedy solution isn&rsquo;t optimal and using the fact that greedy stays ahead as a contradiction.</li>
</ol>
</li>
<li>
<p><strong>Exchange arguments</strong>: This works by showing you can iteratively transform any optimal solution into the result of the greedy algorithm without changing the cost of the optimal solution, thereby proving the greedy solution is optimal.</p>
<ol>
<li><strong>Define your solution</strong> Introduce variables to denote the greedy solution $G$ and the optimal solution $O$ (i.e. for task scheduling, it is the set of tasks).</li>
<li><strong>Compare solutions</strong> Show that $G \neq O$ (i.e. there is some element of $G$ not in $O$. It helps to name this different element).</li>
<li><strong>Exchange pieces</strong> Show how to transform $G$ into $O$, typically by moving element previously defined in $G$ to $O$. Then prove by doing os you did not worsen $O$&rsquo;s optimality, and therefore have a different optimal solution.</li>
<li><strong>Iterate</strong> Argue by continuing the exchange of pieces, you can turn $G$ into $O$ without reducing optimality, and therefore $G$ is optimal.</li>
</ol>
</li>
</ol>
<h1 id="dynamic-programming">Dynamic Programming</h1>
<hr>
<p>Dynamic programming is a method to find optimal solution to problems, from optimal solutions to subproblem. Because sets of subproblems to solve larger problems overlap, each subproblem can be calculated once, it&rsquo;s solutions are stored for next future calls.</p>
<p>Common examples of Dynamic Programming include</p>
<ul>
<li>Dijkstra&rsquo;s algorithm</li>
<li>Integer knapsack</li>
<li>Optimal matrix chain multiplication</li>
</ul>
<h2 id="sample-algorithms-2">Sample Algorithms</h2>
<h3 id="fibonacci">Fibonacci</h3>
<p>Whilst simple this problem showcases the concept of dynamic programming very well.</p>
<p>Create a function <code>fib</code> where given $i$, find the $i^{th}$ fibonacci number. This can be defined with the following mathematical recurrence relation</p>
<p>$$
F_n =
\begin{cases}
0 &amp; \text{if } n = 0 \\
1 &amp; \text{if } n = 1 \\
F_{n - 1} + F_{n - 2} &amp; \text{otherwise}
\end{cases}
$$</p>
<p>or with the following python code</p>
<pre><code class="language-py"># A function to calculate the nth fibonacci number
def fib(n: int) -&gt; int:
    if n == 0:
        return 0
    if n == 1:
        return 1
    return fib(n - 1) + fib(n - 2)
</code></pre>
<p>However, the runtime of this is $O(2^n)$, an exponential runtime, as each function call itself twice until it reaches the base case.</p>
<h4 id="top-down-solution">Top down solution</h4>
<p>In top down dynamic programming, we use the process of <strong>memoisation</strong> (caching previous function call results) to reduce the runtime to $O(n)$, and space complexity of $O(n)$.</p>
<pre><code class="language-py"># Top down solution to find the nth fibonacci number
def fib(n: int) -&gt; int:
    # Create memoisation table and add base cases
    memo = [-1] * n
    memo[0] = 0
    memo[1] = 1
    return dp(n, memo)

def dp(n: int, memo: list[int]) -&gt; int:
    # If we do have not calculated the value before
    if memo[n] == -1:
        memo[n] = dp(n - 1, memo) + dp(n - 2, memo)

    # Now we can simply return the stored value in O(1)
    return memo[n]
</code></pre>
<h4 id="bottom-up-solution">Bottom up solution</h4>
<p>In bottom up DP, we write an iterative solution to compute the value of every subproblem to reduce the runtime to $O(n)$ and space complexity of $O(1)$.</p>
<pre><code class="language-py"># Bottom up solution to find the nth fibonacci number
def fib(n: int) -&gt; int:
    # Base Case
    if n == 0:
        return 0
    if n == 1:
        return 1

    # Iterate up to the nth fibonacci number
    a, b = 0, 1
    for i in range(2, n + 1):
        c = a + b
        a = b
        b = c
    return b
</code></pre>
<h3 id="integer-knapsack">Integer Knapsack</h3>
<p>Given a set of $n$ items with weights and values,</p>
<p>$$I = \{ (v_1, w_1), (v_2, w_2), &hellip;, (v_n, w_n) \},$$</p>
<p>and a knapsack which has a weight capacity of $c$, choose a combination of items, maximising the value of the items while ensuring the total weight is less than $c$.</p>
<p>We can define the following recurrence relation</p>
<p>$$
F(i, c) =
\begin{cases}
0 &amp; \text{if } i = 0 \text{ or } c \leq 0 \\
\max(F(i - 1, c - w_i) + v_i, F(i - 1, c)) &amp; \text{otherwise}
\end{cases}
$$</p>
<p>where</p>
<ul>
<li>$i$ is the index of the current item</li>
<li>$c$ is the current capacity</li>
</ul>
<p>which has the base case that we return 0 if we have no items or we are out of capacity, else we start at an item, and then consider the maximum value we can get if:</p>
<ol>
<li><strong>we include it in the knapsack</strong> in which case, we increase the value we get by the value of the current item, reduce the capacity by the weight of the current item, and then consider what to do with the next item.</li>
<li><strong>we do not include it in the knapsack</strong> in which case, we do nothing, and merely consider what to do with the next item.</li>
</ol>
<p>The runtime of this is unfortunately $O(2^n)$ (since each subproblem makes two recursive calls and it has a maximum depth of $n$), however since there are recalculated subproblems (i.e. when $i$ and $c$ is the same), we can use dynamic programming.</p>
<h3 id="memoisation">Memoisation</h3>
<p>In calculating the $n^{th}$ fibonacci value, there was only one parameter changed in repeated subproblems, therefore we only needed a $n$ sized 1D memoisation table.</p>
<p>However, for the integer knapsack problem, the value of each subproblem is dependent on both $i$ and $c$ so therefore we need a 2D $n \times c$ memoisation table.</p>
<pre><code class="language-py"># Bottom up solution for the integer knapsack problem
def knapsack(items: list[tuple[int, int]], c: int) -&gt; int:
    n = len(items)
    memo = [[0] * (n + 1) for _ in range(c + 1)]

    # Build table in bottom up manner
    for i in range(n + 1):
        for w in range(c + 1):
            i_value, i_weight = items[i]
            # If no more items or remaining capacity is 0
            if i == 0 or w == 0:
                memo[i][w] = 0
            # If we can have the new item without going over capacity
            elif items[i][1] &lt;= w:
                include_v = memo[i - 1][w - i_weight] + i_value
                ignore_v = memo[i - 1][w]
                # Choose the option that gives the most value
                items[i][w] = max(include_v, ignore_v)
            # If we cannot fit any more items
            else:
                memo[i][w] = memo[i - 1][w]

    return memo[n][c]
</code></pre>
<p>Because at <code>memo[i][j]</code> will always be the maximum value the bag can hold, after considering whether to include or not the first <code>i</code> items, and when the bag has a maximum capacity of <code>j</code>, then therefore <code>memo[n][c]</code> will be the maximum value a bag of capacity <code>c</code> can hold after considering all <code>n</code> items.</p>
<h4 id="time-complexity">Time Complexity</h4>
<p>The final time complexity is $O(nc)$ as there is a nested loop that loops $n \times c$ times, and each operation within the loop is $O(1)$ as they all only require $O(1)$ array access or arithmetic.
Note that because the runtime is dependent on the <strong>numeric value</strong> of the input, and not just the <strong>length</strong> of the input size, the runtime of this algorithm is not polynomial, but <strong>pseudo-polynomial</strong>.</p>
<h4 id="space-complexity">Space Complexity</h4>
<p>The space complexity is $O(nc)$ since there is a 2D $n \times c$ memoisation table to store the solutions of previous computations.
It is important to keep in mind that despite the bottom up solution for fibonacci having a space complexity of $O(1)$, the space complexity here is the same as the top down solution as all previous computations need to be remembered.
Similar to runtime, this also has a pseudo-polynomial space complexity.</p>
<h1 id="linear-programming">Linear Programming</h1>
<hr>
<p>Linear programming is an optimisation method to maximise or minimise a linear function (our objective) given linear constraints on variables.</p>
<p>This can be represented in mathematical model with</p>
<table>
<thead>
<tr>
<th>Component</th>
<th>Mathematical Representation</th>
</tr>
</thead>
<tbody>
<tr>
<td>Variables</td>
<td>$x_j \geq 0 \text{ for } 1 \leq j \leq n$</td>
</tr>
<tr>
<td>Objective</td>
<td>$\text{maximise or minimise } \sum^{n}_{j = 1} c_j x_j$</td>
</tr>
<tr>
<td>Constraints</td>
<td>$\sum^{n}_{j = 1} a_{ij} x_j R_i b_i, \text{ for } 1 \leq i \leq m \text{ with } R_i \in \{\leq, =, \geq \}$</td>
</tr>
</tbody>
</table>
<p>A <em>feasible solution</em> is a variable assignment satisfying all constraints.</p>
<p>An <em>optimal solution</em> is a feasible solution satisfying the objective.</p>
<h2 id="canonical-form">Canonical form</h2>
<p>A linear programming formulation can also be represented by the canonical form.</p>
<p>maximise</p>
<p>$$\textbf{c}^\text{T}\textbf{x}$$</p>
<p>subject to the constraints</p>
<p>$$
\begin{align*}
A\textbf{x} &amp; \leq \textbf{b} \\
\textbf{x} &amp; \geq 0.
\end{align*}
$$</p>
<p>where</p>
<p>$$
\textbf{x} =
\begin{pmatrix}
x_1 \\
x_2 \\
\vdots \\
x_n
\end{pmatrix},
\textbf{c} =
\begin{pmatrix}
c_1 \\
c_2 \\
\vdots \\
c_n
\end{pmatrix},
\textbf{b} =
\begin{pmatrix}
b_1 \\
b_2 \\
\vdots \\
b_m
\end{pmatrix},
A =
\begin{pmatrix}
a_{1, 1} &amp; a_{1, 2} &amp; \ldots &amp; a_{1, m} \\
a_{2, 1} &amp; a_{2, 2} &amp; \ldots &amp; a_{2, m} \\
\vdots   &amp; \vdots   &amp; \ddots &amp; \vdots   \\
a_{n, 1} &amp; a_{n, 2} &amp; \ldots &amp; a_{n, m}
\end{pmatrix}.
$$</p>
<h2 id="runtime-1">Runtime</h2>
<p>Solving a LP (Linear Programming) formulation is in <strong>P</strong> (has a polynomial runtime), whilst solving an ILP (Integer Linear Programming - similar to LP, except that all the variables must be integers) formulation is in <strong>NP</strong>.</p>
<p>In practice, given an optimisation problem, a person formulates the linear programming problem, which is then given to an LP solver which uses algorithms such as the simplex algorithm.</p>
<h1 id="reductions">Reductions</h1>
<hr>
<p>Reductions are the conversion of one problem to another. An efficient reduction from A to B may be used to show that B is at least as difficult as A.</p>
<h2 id="complexity-classes">Complexity Classes</h2>
<h3 id="p-polynomial">P (Polynomial)</h3>
<p>A problem $A(n)$ is in class P, denoted by $A \in \mathbf{P}$, if there is an algorithm which solve it in polynomial time with regard to the size of the input.</p>
<h3 id="np-non-deterministic-polynomial-time">NP (Non deterministic Polynomial Time)</h3>
<p>A problem $A(n)$ is in class NP, denoted by $A \in \mathbf{NP}$, if there is an algorithm which can verify if a solution is correct or not in polynomial time with regard to the size of the input.</p>
<ul>
<li>A problem that is in P is also in NP.</li>
<li>Hence, NP problems are at least as hard as P problems.</li>
</ul>
<h3 id="np-hard-and-np-complete">NP-Hard and NP-Complete</h3>
<p>A problem is NP-Hard if any problem in NP is reducible to it (informally, a problem is NP-Hard if it it is at least as hard as the hardest problems in NP).</p>
<p>A problem is NP-Complete if it is in both NP, and NP-Hard (informally, a problem is NP-Complete if it is one of the hardest problems in NP, the &ldquo;complete&rdquo; meaning that it is able to simulate any problem in the same complexity class through reductions).</p>
<ul>
<li>Hence, NP-Hard problems are at least as hard as NP-Complete.</li>
</ul>
<h2 id="np-problems">NP Problems</h2>
<h3 id="3sat">3SAT</h3>
<p>The SAT problem is: Given a propositional formula in the CNF form $C_1 \land C_2 \land &hellip; \land C_n$ where each clause $C_i$ is a disjunction of propositional variables or their negations, i.e.</p>
<p>$$
(P_1 \lor \lnot P_2 \lor P_3 \lor \lnot P_5) \land (P_2 \lor P_3 \lor \lnot P_5 \lor \lnot P_6) \land (\lnot P_3 \lor \lnot P_4 \lor P_5)
$$</p>
<p>Is there some assignment of boolean values to $P_1, P_2, &hellip;, P_6$ which makes the formula true?</p>
<p>If each clause involves exactly 3 variables, then this problem is 3SAT.</p>
<h2 id="cooks-theorem-1982-turing-award">Cook&rsquo;s Theorem (1982 Turing Award)</h2>
<p>Theorem: Every NP problem is polynomially reducible ot the SAT problem</p>
<p>This means that if the SAT problem is solvable in polynomial time, P = NP, as other NP problems can be reduced to SAT in polynomial time and then solved in polynomial time.</p>
<h2 id="karps-21-problems-1972-1985-turing-award">Karp&rsquo;s 21 Problems [1972] (1985 Turing Award)</h2>
<p>Karp&rsquo;s 21 problems are a set of problems which show that there is a many-one reduction from the SAT problem to other NP problems, therefore showing they are all NP-complete.</p>
<ul>
<li>Satisfiability
<ul>
<li>0 - 1 Integer Programming</li>
<li>Clique
<ul>
<li>Set Packing</li>
<li>Vertex Cover
<ul>
<li>Set Cover</li>
<li>Feedback Node set</li>
<li>Feedback Arc Set</li>
<li>Direct Hamiltonian Cycle
<ul>
<li>Undirected Hamiltonian Cycle</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>3SAT
<ul>
<li>Graph Coloring
<ul>
<li>Clique Cover</li>
<li>Exact cover
<ul>
<li>Hitting Set</li>
<li>Steiner Tree</li>
<li>3D Match</li>
<li>Subset Sum
<ul>
<li>Job Sequencing</li>
<li>Partition
<ul>
<li>Max Cut</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="3gc-to-sat-reduction">3GC to SAT Reduction</h2>
<p>3GC AKA 3 Graph Colouring is a problem that asks given an undirected graph $G = (V, E)$, and a set of colours $C = \{r, g, b\}$, is there a function $f: V \rightarrow C$ such that if $(v, w) \in E$ then $f(v) \neq f(w)$.</p>
<p>Using the notation that $v_i$ is a proposition that is <code>true</code> if vertex $v$ is the colour $i$, we can use the following rules to complete the reduction.</p>
<ol>
<li>Enforce that each vertex is <strong>one colour only</strong>.
We can enforce this through 2 rules.
<ol>
<li>A vertex is <strong>no more than one colour</strong>:
$$\forall v \in V : (\lnot v_1 \lor \lnot v_2) \land (\lnot v_1 \lor \lnot v_3) \land (\lnot v_2 \land \lnot v_3)$$
If any of the vertices are more than one colour, then both propositions will be <code>true</code> inside the clause. Since we take the negation of the proposition, both propositions are evaluated as <code>false</code>, and their disjunction evaluates to <code>false</code>.</li>
<li>A vertex is <strong>at least one colour</strong>:
$$\forall v \in V : (v_1 \lor v_2 \lor v_3)$$
If a vertex is not any colour, then the clause evaluates to <code>false</code>.</li>
</ol>
</li>
<li>Enforce that <strong>adjacent vertices are not the same colour</strong>.
$$\forall (v, w) \in E : (\lnot v_1 \lor \lnot w_1) \land (\lnot v_2 \lor w_2) \land (\lnot v_3 \lor \lnot w_3)$$
Similar to 1.a, if any adjacent vertices are the same colour, then the clause evaluates to <code>false</code>.</li>
</ol>
]]></content></item><item><title>All Pairs Shortest Paths, Rings and Semi Rings</title><link>https://zes1092.github.io/posts/all-pairs-shortest-paths-rings-and-semi-rings/</link><pubDate>Wed, 02 Mar 2022 00:00:00 +0000</pubDate><guid>https://zes1092.github.io/posts/all-pairs-shortest-paths-rings-and-semi-rings/</guid><description>Introduction The Single Source Shortest Paths (SSSP) problem is to find the shortest distance from one node to every other node in a graph. The All Pairs Shortest Paths (APSP) problem, is to determine for every node in the graph, the shortest distance to every other node in a graph. APSP typically has applications in routing algorithms, i.e. finding the shortest path from one location to another.
Usual algorithms Depending on the type of graph, for both SSSP and APSP there are different algorithms to solve the relevant problems.</description><content type="html"><![CDATA[<h2 id="introduction">Introduction</h2>
<p>The Single Source Shortest Paths (SSSP) problem is to find the shortest distance from one node to every other node in a graph. The All Pairs Shortest Paths (APSP) problem, is to determine for every node in the graph, the shortest distance to every other node in a graph. APSP typically has applications in routing algorithms, i.e. finding the shortest path from one location to another.</p>
<h2 id="usual-algorithms">Usual algorithms</h2>
<p>Depending on the type of graph, for both SSSP and APSP there are different algorithms to solve the relevant problems. The tables below provide the fastest well known algorithm to solve SSSP and APSP</p>
<h3 id="single-source-shortest-path">Single Source Shortest Path</h3>
<table>
<thead>
<tr>
<th>Graph Type</th>
<th>Algorithm</th>
<th>Runtime</th>
</tr>
</thead>
<tbody>
<tr>
<td>Unweighted</td>
<td>BFS</td>
<td>$O(E)$</td>
</tr>
<tr>
<td>Non Negative Edge Weights</td>
<td>Dijkstra&rsquo;s</td>
<td>$O(V \text{lg} V + E)$</td>
</tr>
<tr>
<td>General</td>
<td>Bellman-Ford</td>
<td>$O(VE)$</td>
</tr>
<tr>
<td>Directed Acyclic Graph (DAG)</td>
<td>Topological Sort + Bellman-Ford</td>
<td>$O(V + E)$</td>
</tr>
</tbody>
</table>
<h3 id="all-pairs-shortest-path">All Pairs Shortest Path</h3>
<p>Ignoring DAGs, the first two algorithms for APSP are merely SSSP algorithms run from every vertex of the graph, whilst there are different algorithms for general graphs depending on the number of edges. It is also important to note that as the number of edges increases to $O(V^2)$ in a graph, Johnson&rsquo;s algorithm approaches $O(V^2 \text{lg} V + V^3)$, making it slower than Floyd-Warshall.</p>
<table>
<thead>
<tr>
<th>Graph Type</th>
<th>Algorithm</th>
<th>Runtime</th>
</tr>
</thead>
<tbody>
<tr>
<td>Unweighted</td>
<td>$|V| \times$ BFS</td>
<td>$O(VE)$</td>
</tr>
<tr>
<td>Non Negative Edge Weights</td>
<td>$|V| \times$ Dijkstra&rsquo;s</td>
<td>$O(V^2 \text{lg} V + VE)$</td>
</tr>
<tr>
<td>General (Dense)</td>
<td>Floyd-Warshall</td>
<td>$O(V^3)$</td>
</tr>
<tr>
<td>General (Sparse)</td>
<td>Johnson&rsquo;s</td>
<td>$O(V^2 \text{lg} V + VE)$</td>
</tr>
</tbody>
</table>
<h2 id="floyd-warshall-and-matrix-multiplication">Floyd-Warshall and Matrix Multiplication</h2>
<p>That being said a special shout out goes to Floyd-Warshall for it&rsquo;s simplicity - elegantly composed of a few lines of code.</p>
<pre><code class="language-py"># Implementation of the Floyd-Warshall algorithm in Python

def floyd_warshall(graph: list[list[int]]):
    n = len(graph)
    for k in range(n):
        for j in range(n):
            for i in range(n):
                graph[i][j] = min(graph[i][j], graph[i][k] + graph[k][j])
</code></pre>
<p>It shares a structure very similar to Matrix Multiplication (MM) if the two given matrices are square matrices (which is always the case for Floyd-Warshall as all adjacency matrices are square).</p>
<pre><code class="language-py"># Implementation of matrix multiplication for square matrices

def matrix_mul(A: list[list[int]], B: list[list[int]]) -&gt; list[list[int]]:
    n = len(A)
    C = [[0] * n for _ in range(n)]
    for i in range(n):
        for j in range(n):
            for k in range(n):
                C[i][j] = sum(C[i][j], A[i][k] * B[k][j])
    return C
</code></pre>
<p>With the exception of creating result matrix and storing the calculations there, the algorithms both run in $O(V^3)$, except for two differences in operation</p>
<ol>
<li>Instead of taking the cumulative <code>sum</code>, Floyd-Warshall takes the cumulative <code>min</code></li>
<li>Instead of applying <code>*</code> between two values, Floyd-Warshall applies <code>+</code></li>
</ol>
<h2 id="strassens-algorithm">Strassen&rsquo;s Algorithm</h2>
<p>That being said there exists a sub $O(V^3)$ time for calculating the MM of two matrices, known as Strassen&rsquo;s algorithm. It is important to note that naive MM runs in $O(V^3)$, whilst matrix addition / subtraction runs in $O(V^2)$, and so Strassen&rsquo;s algorithm aims to reuse computations and lower runtime by using less multiplications, but more addition / subtraction.</p>
<h3 id="explanation">Explanation</h3>
<p>The naive method of MM is as follows</p>
<p>Given the $n \times n$ matrices $A$ and $B$, to calculate their product, we can split each matrix into smaller block matrices in each quadrant (i.e. $A_{1, 1}$ is the smaller $\frac{n}{2} \times \frac{n}{2}$ matrix in the top left of A).</p>
<p>$$
A =
\begin{bmatrix}
A_{1, 1} A_{1, 2} \\
A_{2, 1} A_{2, 2}
\end{bmatrix}
,
B =
\begin{bmatrix}
B_{1, 1} B_{1, 2} \\
B_{2, 1} B_{2, 2}
\end{bmatrix}
,
C =
\begin{bmatrix}
C_{1, 1} C_{1, 2} \\
C_{2, 1} C_{2, 2}
\end{bmatrix}
$$</p>
<p>As a result the naive algorithm requires 8 multiplications (and 4 additions).</p>
<ol>
<li>$C_{1, 1} = A_{1, 1}B_{1, 1} + A_{1, 2}B_{2, 1}$</li>
<li>$C_{1, 2} = A_{1, 1}B_{1, 2} + A_{1, 2}B_{2, 2}$</li>
<li>$C_{2, 1} = A_{2, 1}B_{1, 1} + A_{2, 2}B_{2, 1}$</li>
<li>$C_{2, 2} = A_{2, 1}B_{1, 2} + A_{2, 2}B_{2, 2}$</li>
</ol>
<p>In comparison, Strassen&rsquo;s algorithm requires 7 multiplications (and 18 additions / subtractions) by creating temporary matrices</p>
<ol>
<li>$M_1 = (A_{1, 1} + A_{2, 2})(B_{1 ,1} + B_{2, 2})$</li>
<li>$M_2 = (A_{2, 1} + A_{2, 2})(B_{1, 1})$</li>
<li>$M_3 = (A_{1 ,1})(B_{1, 2} - B_{2, 2})$</li>
<li>$M_4 = (A_{2, 2})(B_{1, 2} - B_{2, 2})$</li>
<li>$M_5 = (A_{1, 1} + A_{1, 2})(B_{2, 2})$</li>
<li>$M_6 = (A_{2, 1} - A_{1, 1})(B_{1, 1} + B_{1, 2})$</li>
<li>$M_7 = (A_{1, 2} - A_{2, 2]})(B_{2, 1} + B_{2, 2})$</li>
</ol>
<p>which can then be added and subtracted with each other to produce the final result</p>
<ol>
<li>$C_{1, 1} = M_1 + M_4 - M_5 + M_7$</li>
<li>$C_{1, 2} = M_3 + M_5$</li>
<li>$C_{2, 1} = M_2 + M_4$</li>
<li>$C_{2, 2} = M_1 - M_2 + M_3 + M_6$</li>
</ol>
<h3 id="time-complexity">Time Complexity</h3>
<p>The final runtime of the aforementioned algorithms can be determined through the master&rsquo;s theorem
$$T(n) = aT \left( \frac{n}{b} \right) + f(n)$$
Where</p>
<ul>
<li>$a$ = Number of subproblems (no.# of smaller MMs required per subproblem)</li>
<li>$b$ = Reduction in size per problem (2, as the smaller matrixes have size $\frac{n}{2}$)</li>
<li>$f(n)$ = Cost of work per problem ($O(n^2)$, as we do matrix addition / subtraction)</li>
</ul>
<table>
<thead>
<tr>
<th></th>
<th>Naive Solution</th>
<th>Strassen&rsquo;s Algorithm</th>
</tr>
</thead>
<tbody>
<tr>
<td>Recurrence Relation</td>
<td>$T(n) = 8T \left( \frac{n}{2} \right) + O(n^2)$</td>
<td>$T(n) = 7T \left( \frac{n}{2} \right) + O(n^2)$</td>
</tr>
<tr>
<td>Time Complexity</td>
<td>$O(n^3)$</td>
<td>$O(n^{\text{lg}7}) \approx O(n^{2.807})$</td>
</tr>
</tbody>
</table>
<p>Not bad! We have managed to reduce the runtime to $O(n^{2.807})$, and there are algorithms that can achieve even lower asymptotic runtime (i.e. the Vassilevska Williams has a runtime of $O(n^{2.373}$), though their hidden constant times make them impractical. Now would it be possible to apply this to Floyd-Warshall?</p>
<p>Note: $n = V$, as $V$ is the number of vertices, which is the number of rows and columns in an adjacency matrix.</p>
<h2 id="rings-and-semi-rings">Rings and Semi-Rings</h2>
<p>The issue is that fast matrix multiplication can only be applied to any ring.</p>
<p>In mathematics, a ring is a set that</p>
<ul>
<li>has addition which must be commutative and associative</li>
<li>has multiplication that must be associative</li>
<li>has a zero (aka the identity element)</li>
<li>has negatives (i.e. adding an element and it&rsquo;s negative produces the ring&rsquo;s zero element)</li>
<li>has two distributive laws relating addition and multiplication</li>
</ul>
<p>However, for APSP, it is usually defined in a semi-ring. The definition of a semi-ring is the same as a ring, but <strong>without the requirement for a negative</strong>.</p>
<p>This becomes relevant as the Strassen&rsquo;s reduces matrix multiplications by taking advantage of matrix subtractions as the <strong>negative</strong> of the <code>sum</code> to reuse calculations.
Looking back at our comparison between Floyd-Warshall and MM, we must therefore need a negative to <code>min</code> in order to apply Strassen&rsquo;s to APSP, which unfortunately does not exist, so we cannot apply fast MMs to APSP.</p>
<p>But what if we could define APSP in the domain of a ring?</p>
<h2 id="transitive-closure">Transitive Closure</h2>
<p>Don&rsquo;t worry, I didn&rsquo;t drag you through all that to learn 0 applications.
The Transitive Closure for an adjacency matrix $G$ is an adjacency matrix $G&rsquo;$, where $G&rsquo;_{i, j} = 1$ if there is a path from $v_i$ to $v_j$ in $G$.</p>
<p>Due to the simplicity of this problem, this can be implemented through an algorithm using boolean operations as shown below.</p>
<h3 id="comparison-with-mm">Comparison with MM</h3>
<pre><code class="language-py"># Implementation of a function to &quot;square&quot; a boolean matrix

def boolean_matrix_squaring(graph: list[list[bool]]):
    n = len(graph)
    for k in range(n):
        for j in range(n):
            for i in range(n):
                graph[i][j] = graph[i][j] or (graph[i][k] and graph[k][j])
</code></pre>
<p>We can compare this to our MM implementation and note two differences</p>
<ol>
<li>Instead of taking the cumulative <code>sum</code>, we take the cumulative <code>or</code></li>
<li>Instead of applying <code>*</code> between two values, we apply <code>and</code></li>
</ol>
<p>The issue earlier was that fast MM is only defined for a ring, however TC is also <a href="http://math.mit.edu/~jerison/103/handouts/rings.pdf">defined under a ring with boolean operations</a>, and as a result we can apply Strassen&rsquo;s algorithm to the TC problem.</p>
<h3 id="application">Application</h3>
<p>Now we can attempt to apply Strassen&rsquo;s algorithm to quickly find the TC of a graph.</p>
<h4 id="applying-with-strassens">Applying with Strassen&rsquo;s</h4>
<p>To find the TC, we can more or less represent <code>true</code> with <code>1</code>, <code>false</code> with <code>0</code>, and then apply Strassen&rsquo;s algorithm to multiply the adjacency matrix with itself, always taking <code>mod 2</code> of the results in $O(V^{2.807})$.</p>
<p>The result of adjacency matrix multiplication produces the a matrix where $A_{i, j}$ represents if there is a path of length 2 from $v_i$ to $v_j$.</p>
<h4 id="reduction-from-tc-to-mm">Reduction from TC to MM</h4>
<p>Now it is possible to reduce (apply an algorithm to convert from one problem to another) the TC problem to MM by following the following steps.</p>
<ol>
<li>
<p>Replace all strongly connected components with a single vertex in $O(V^2)$.</p>
</li>
<li>
<p>Topological sort the graph so edges move from lowered numbered vertices go to higher numbered ones in $O(V + E)$.</p>
</li>
<li>
<p>As a result, the adjacency matrix is an upper triangular matrix (as vertices only have a path to higher numbered vertices) $G$, which is can be composed of 4 quadrants:</p>
<p>$$
G =
\left[ \begin{array}{c | c}
A &amp; C \\
\hline
0 &amp; B \\
\end{array} \right],
$$</p>
<p>where $A$ is the adjacency matrix for vertices $v_1, &hellip; v_{n/2}$, and $B$ for $v_{(n/2) + 1}, &hellip;, v_{n - 1}$.
Meanwhile C represents the edges from the vertices in $A$ to $B$.</p>
</li>
</ol>
<p>Now, we claim that the TC of $G$:</p>
<p>$$
G&rsquo; =
\left[ \begin{array}{c | c}
A&rsquo; &amp; A&rsquo; C B&rsquo; \\
\hline
0 &amp; B&rsquo; \\
\end{array} \right].
$$</p>
<p>This is because the TC of $A$ is solely dependent on connections in $A$, and the same applies for $B$.</p>
<p>As for the upper right matrix, $C_{i, j}$ will be <code>true</code> if there is a path from $v_i$ to $v_j$, which is true if there is a path from $v_i$ to some vertex in $A&rsquo;$, which has a path to some other vertex in $B&rsquo;$ which is connected to $v_j$.</p>
<p>This path can be determined by taking the multiplication $A&rsquo; \times C \times B&rsquo;$ as $A&rsquo;$, hence $C&rsquo; = A&rsquo; C B&rsquo;$.</p>
<p>Since $G&rsquo;$ can be calculated recursively by finding the TC of 2 half sized graphs ($A&rsquo;$, $B&rsquo;$) and 2 MMs ($A&rsquo; C B&rsquo;$), the final time complexity is represented by the recurrence relation</p>
<p>$$
T(n) = 2T \left( \frac{n}{2} \right) + O \left( n^{2.807} \right)
$$</p>
<p>which can be calculated to be $O(n^{2.803})$, the same runtime as the MM algorithm used! In fact, <a href="https://www.cs.bgu.ac.il/~dinitz/Course/SS-12/transitiveClosure.pdf">TC is reducible to boolean MM</a>.</p>
<h3 id="repeated-dfs">Repeated DFS</h3>
<p>That being said, it is possible to apply DFS on every vertex of the graph to find the TC. However a single DFS of a graph has a runtime of $O(V + E)$ (which can be $O(V)$ for sparse graphs and $O(V^2)$ for dense graphs), and so the total runtime would be $O(V^2)$ for sparse graphs and $O(V^3)$ for dense graphs.</p>
<p>As a result the suitable algos for finding the Transitive Closure of a graph is listed below.</p>
<table>
<thead>
<tr>
<th></th>
<th>Dense Graphs</th>
<th>Sparse Graphs</th>
</tr>
</thead>
<tbody>
<tr>
<td>Algorithm</td>
<td>Strassen&rsquo;s</td>
<td>Repeated DFS</td>
</tr>
<tr>
<td>Runtime</td>
<td>$O(V^{2.807})$</td>
<td>$O(V^2)$</td>
</tr>
</tbody>
</table>
<h2 id="conclusion">Conclusion</h2>
<p>In conclusion, we&rsquo;ve now learn that we can apply fast MMs to other problems defined in a ring, one of which was allowing us to find the TC of a dense graph quickly by reducing the problem to MM.</p>
]]></content></item><item><title>for her</title><link>https://zes1092.github.io/posts/for-her/</link><pubDate>Mon, 20 Dec 2021 00:00:00 +0000</pubDate><guid>https://zes1092.github.io/posts/for-her/</guid><description>The dilemma for me was deciding when the stress of a relationship outweighs the love. How do you know when you&amp;rsquo;re just better off by yourself?
I learned the answer is success just has no time for emotions. People get on top of any industry by working algorithmically. But most likely you&amp;rsquo;re like me where horny and lonely is enough to pause your whole life. The reason I made this, is it forces me to reflect and be objective with my first relationship instead of being petty.</description><content type="html"><![CDATA[<p>The dilemma for me was deciding when the stress of a relationship outweighs the love. How do you know when you&rsquo;re just better off by yourself?</p>
<p>I learned the answer is success just has no time for emotions. People get on top of any industry by working algorithmically. But most likely you&rsquo;re like me where horny and lonely is enough to pause your whole life. The reason I made this, is it forces me to reflect and be objective with my first relationship instead of being petty. What I really want to do is villianize her in my head and fixate on all the bad things, yet the reality is I was closer with her than I was with any other human in that time period. I travelled with her, pillow talked every night, matured and learned about each other. Now we don&rsquo;t even speak. I know our experiences will stay with me forever and that&rsquo;s the part I should remember.</p>
<blockquote>
<p><em><strong>My chapter with her is now over and it was a good one.</strong></em></p>
</blockquote>
]]></content></item></channel></rss>